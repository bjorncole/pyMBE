{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b29b3fe-4145-499c-90f9-a383a8d3ca02",
   "metadata": {},
   "source": [
    "# Annex A Execution\n",
    "\n",
    "A notebook implementing the execution rules from KerML Annex A with PyMBE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7839ebb-7c5b-4284-9ca4-5a83c53cb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymbe.api as pm\n",
    "\n",
    "import copy\n",
    "\n",
    "from importlib import resources as lib_resources\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Any, Collection, Dict, List, Tuple, Union\n",
    "\n",
    "from pymbe.model import Model, Element\n",
    "from pymbe.model_modification import *\n",
    "\n",
    "from pymbe.query.metamodel_navigator import is_type_undefined_mult, \\\n",
    "                                    is_multiplicity_one, \\\n",
    "                                    is_multiplicity_specific_finite, \\\n",
    "                                    get_finite_multiplicity_types, \\\n",
    "                                    identify_connectors_one_side, \\\n",
    "                                    get_lower_multiplicity, \\\n",
    "                                    get_upper_multiplicity, \\\n",
    "                                    does_behavior_have_write_features, \\\n",
    "                                    get_most_specific_feature_type, \\\n",
    "                                    has_type_named, \\\n",
    "                                    get_effective_lower_multiplicity, \\\n",
    "                                    get_feature_bound_values, \\\n",
    "                                    get_more_general_types\n",
    "\n",
    "from pymbe.metamodel import derive_inherited_featurememberships\n",
    "\n",
    "from pymbe.interpretation.working_maps import FeatureTypeWorkingMap\n",
    "from pymbe.interpretation.execute_kerml_atoms import KermlForwardExecutor\n",
    "\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58774846-db97-4e49-b8da-6eef42b2b0b0",
   "metadata": {},
   "source": [
    "## Key Helpers for the Algorithm\n",
    "\n",
    "These helpers are yet to be implemented in the core of the Python tool and thus need to be more spelled out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c53c5-b093-45b3-8026-2cea43082b3d",
   "metadata": {},
   "source": [
    "### Check for Connectors to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b787a36-0513-48b7-bf60-3793ccc30c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_feature_connected(feature):\n",
    "    print(f\"...Inspecting {feature.declaredName} for connector references.\")\n",
    "    if hasattr(feature, \"reverseReferenceSubsetting\"):\n",
    "        print(f\"...Found link to connector end {feature.reverseReferenceSubsetting[0]}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"...Found no reverse edge outgoing to connector end.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0ffdb-28d1-4454-bcb0-6bf2e1c492b9",
   "metadata": {},
   "source": [
    "### Identify Important Metatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58066cfa-b4d2-47a5-be4a-643d4372d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_metas():\n",
    "    return {'Feature', 'Step'}\n",
    "\n",
    "def classifier_metas():\n",
    "    return {'Classifier', 'Behavior', 'Structure'}\n",
    "\n",
    "def assoc_metas():\n",
    "    return {'Association'}\n",
    "\n",
    "def connector_metas():\n",
    "    return {'Connector', 'Succession'}\n",
    "\n",
    "def datatype_metas():\n",
    "    return {'DataType'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b970d71-5689-4ad6-8d7b-108a75f19ffc",
   "metadata": {},
   "source": [
    "### Print atoms as if in KerML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7019f-c443-468c-87a9-e24ba6fabb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_kerml_atom(atom_to_print):\n",
    "    \n",
    "    atom_string = \"#atom\\n\"\n",
    "    \n",
    "    if hasattr(atom_to_print, \"throughUnioning\"):\n",
    "        atom_string = \"\"\n",
    "    \n",
    "    if atom_to_print._metatype == \"Classifier\":\n",
    "        atom_string = atom_string + \"classifier \"\n",
    "    elif atom_to_print._metatype == \"Behavior\":\n",
    "        atom_string = atom_string + \"behavior \"\n",
    "    elif atom_to_print._metatype == \"Association\":\n",
    "        atom_string = atom_string + \"association \"\n",
    "    elif atom_to_print._metatype == \"Succession\":\n",
    "        atom_string = atom_string + \"succession \"\n",
    "    elif atom_to_print._metatype == \"Structure\":\n",
    "        atom_string = atom_string + \"struct \"\n",
    "    elif atom_to_print._metatype == \"DataType\":\n",
    "        atom_string = atom_string + \"datatype \"\n",
    "    \n",
    "    atom_string = atom_string + atom_to_print.basic_name\n",
    "    \n",
    "    if len(atom_to_print.throughSubclassification) > 0:\n",
    "        atom_string = atom_string + \" specializes \" + \\\n",
    "            \", \".join([sub.basic_name for sub in atom_to_print.throughSubclassification])\n",
    "        \n",
    "    if hasattr(atom_to_print, \"throughUnioning\"):\n",
    "        atom_string = atom_string + \" unions \" + \\\n",
    "            \", \".join([sub.basic_name for sub in atom_to_print.throughUnioning])\n",
    "    \n",
    "    if len(atom_to_print.throughFeatureMembership) > 0:\n",
    "        atom_string = atom_string + \" {\\n\"\n",
    "        for feature in atom_to_print.throughFeatureMembership:\n",
    "            if feature._metatype == \"Feature\":\n",
    "                atom_string = atom_string + \"   feature \"\n",
    "            elif feature._metatype == \"Step\":\n",
    "                atom_string = atom_string + \"   step \"\n",
    "            elif feature._metatype == \"Connector\":\n",
    "                atom_string = atom_string + \"   connector \"\n",
    "            elif feature._metatype == \"Succession\":\n",
    "                atom_string = atom_string + \"   succession \"\n",
    "                \n",
    "            if len(feature.throughFeatureTyping) > 0:\n",
    "                atom_string = atom_string + feature.basic_name + \" : \" + feature.throughFeatureTyping[0].basic_name\n",
    "            else:\n",
    "                atom_string = atom_string + feature.basic_name\n",
    "                \n",
    "            if len(feature.throughRedefinition) > 0:\n",
    "                atom_string = atom_string + \" redefines \" + \\\n",
    "                    \", \".join([sub.basic_name for sub in feature.throughRedefinition])\n",
    "                \n",
    "            if hasattr(feature, \"throughFeatureChaining\"):\n",
    "                atom_string = atom_string + \" chains \" + \\\n",
    "                    str(feature.throughFeatureChaining[0])\n",
    "                \n",
    "            if len(feature.throughFeatureValue) > 0:\n",
    "                atom_string = atom_string + \" = \" + \\\n",
    "                    str(feature.throughFeatureValue[0])\n",
    "                \n",
    "            atom_string = atom_string + \";\\n\"\n",
    "        atom_string = atom_string + \"}\\n\"\n",
    "    elif hasattr(atom_to_print, \"throughEndFeatureMembership\"):\n",
    "        atom_string = atom_string + \" {\\n\"\n",
    "        for feature in atom_to_print.throughEndFeatureMembership:\n",
    "            if feature._metatype == \"Feature\":\n",
    "                atom_string = atom_string + \"   end feature \"\n",
    "            elif feature._metatype == \"Step\":\n",
    "                atom_string = atom_string + \"   step \"\n",
    "            elif feature._metatype == \"Connector\":\n",
    "                atom_string = atom_string + \"   connector \"\n",
    "                \n",
    "            if hasattr(feature, \"throughFeatureTyping\"):\n",
    "                atom_string = atom_string + feature.basic_name + \" : \" + feature.throughFeatureTyping[0].basic_name\n",
    "            else:\n",
    "                atom_string = atom_string + feature.basic_name\n",
    "                \n",
    "            if len(feature.throughRedefinition) > 0:\n",
    "                atom_string = atom_string + \" redefines \" + \\\n",
    "                    \", \".join([sub.basic_name for sub in feature.throughRedefinition])\n",
    "                \n",
    "            atom_string = atom_string + \";\\n\"\n",
    "                \n",
    "        atom_string = atom_string + \"}\\n\"\n",
    "    else:\n",
    "        atom_string = atom_string + \";\\n\"\n",
    "        \n",
    "    return atom_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caea0ba-ebf3-473e-93d6-f4f02037ab92",
   "metadata": {},
   "source": [
    "# Load up Kernel Libraries\n",
    "\n",
    "Load up the model libraries into memory so that key features for subsetting can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9067b-6355-4b9d-9ef4-46cbdb353ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = \"KernelLibrary\"\n",
    "\n",
    "library_model = None\n",
    "\n",
    "with lib_resources.path(\"pymbe.static_data\", \"KernelLibrary.json\") as lib_data:\n",
    "    library_model = pm.Model.load_from_post_file(lib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf018c2-6bb6-49a4-9358-02ba6a991b13",
   "metadata": {},
   "source": [
    "## Routines for Execution\n",
    "\n",
    "The following sections are focused on solving the problem of mapping values to KerML types in the model. The approach taken here is to find one legal set of values for types in the model via an approach where the program will walk straight ahead in the model, deriving values as it goes. This approach is called \"execution\" here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed355d-9336-4b4e-9b58-cbbb2be0364e",
   "metadata": {},
   "source": [
    "## TODO: Add Atom Procedure for Self\n",
    "\n",
    "If a library is used in one of this examples with occurrences, portionOfLife goes into an infinite loop because each portionOfLife has portionOfLife as an inherited Feature. This might be groundable by have the \"self\" Feature already populated so there is something to which selfLinks can bind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e6149-69a9-491d-88c1-bec6803fa8d7",
   "metadata": {},
   "source": [
    "### Atom Generation Procedure for Steps 1 through 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa57c31-f086-47cf-b068-9f57ea269d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_type_for_atom_rev_2(input_model,\n",
    "                          package_to_execute,\n",
    "                          package_to_populate,\n",
    "                          atom_index,\n",
    "                          cf,\n",
    "                          considered_type,\n",
    "                          bound_features_to_atom_values_dict):\n",
    "    \n",
    "    new_ft_classifier = None\n",
    "    \n",
    "    type_name = \"None\"\n",
    "    if considered_type is not None:\n",
    "        type_name = considered_type.basic_name\n",
    "        \n",
    "    if has_type_named(cf, \"Life\"):\n",
    "        print(\"Need to implement a method to generate Life values for Occurrences.\")\n",
    "        return {}\n",
    "        \n",
    "    cf_name = cf.basic_name\n",
    "    \n",
    "    lower_features = cf.feature\n",
    "    \n",
    "    #if cf._id not in values_dict_passed:\n",
    "        \n",
    "    new_ft_classifier = build_from_classifier_pattern(\n",
    "        owner=package_to_populate,\n",
    "        name=f\"My{type_name}{atom_index + 1}\",\n",
    "        model=input_model,\n",
    "        specific_fields={},\n",
    "        metatype=considered_type._metatype,\n",
    "        superclasses=[considered_type]\n",
    "    )\n",
    "\n",
    "    #if is_feature_connected(cf):\n",
    "    if cf._id in bound_features_to_atom_values_dict:\n",
    "        bound_features_to_atom_values_dict[cf._id].append(new_ft_classifier)\n",
    "    else:\n",
    "        bound_features_to_atom_values_dict.update({cf._id: [new_ft_classifier]})\n",
    "\n",
    "    print(f\"Executing step 3a. Creating atom #{atom_index + 1} to be value for {cf_name} and specializing \" + \\\n",
    "          f\"{type_name}\")\n",
    "    \n",
    "    #apply this to the redefined properties also\n",
    "    \n",
    "    for redef in cf.throughRedefinition:\n",
    "        print(f\"Found redefined feature for {cf_name}.\")\n",
    "        if redef._id in bound_features_to_atom_values_dict:\n",
    "            bound_features_to_atom_values_dict[redef._id].append(new_ft_classifier)\n",
    "        else:\n",
    "            bound_features_to_atom_values_dict.update({redef._id: [new_ft_classifier]})\n",
    "    \n",
    "    if len(lower_features) == 0:\n",
    "        print(f\"...No lower features found for {cf}. Will finish descent here.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"...Lower features found for {cf}. Will evaluate it value generation.\")\n",
    "        #for lf in lower_features:\n",
    "        generate_values_for_type_annex_a(input_model,\n",
    "                                         package_to_execute,\n",
    "                                         package_to_populate,\n",
    "                                         cf,\n",
    "                                         atom_index,\n",
    "                                         bound_features_to_atom_values_dict)\n",
    "    \n",
    "    return bound_features_to_atom_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d967a04-4a3c-4429-bf87-a6f94b154695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_existing_values_for_feature(feat, values_dict):\n",
    "    \n",
    "    print(f\"...Looking to see if {feat} is bound to other feature values\")\n",
    "    \n",
    "    values_in_dict = []\n",
    "    feature_values_shared = False\n",
    "    \n",
    "    print(f\"...Feature values for {feat} are {feat.throughFeatureValue}\")\n",
    "    \n",
    "    for bound_val in feat.throughFeatureValue:\n",
    "        if bound_val._metatype == 'FeatureReferenceExpression':\n",
    "            print(f\"...Found a feature value bound to feature {feat}\")\n",
    "            referred_item = bound_val.throughMembership[0]\n",
    "            feature_values_shared = True\n",
    "        elif 'Literal' in bound_val._metatype:\n",
    "            print(f\"...Found literal value for {feat}\")\n",
    "\n",
    "    if feature_values_shared:\n",
    "        print(f\"...Taking values from {referred_item} to match to values set for {feat} ({feat._id})\")\n",
    "        try:\n",
    "            values_in_dict = values_dict[referred_item._id]\n",
    "            print(f\"...Found values {values_in_dict} to match to values set for {feat} ({feat._id})\")\n",
    "            try:\n",
    "                values_dict[feat._id] = values_dict[feat._id] + values_in_dict\n",
    "            except KeyError:\n",
    "                values_dict.update({feat._id: values_in_dict})\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        #apply this to the redefined properties also\n",
    "    \n",
    "        for redef in feat.throughRedefinition:\n",
    "            print(f\"Found redefined feature for {feat}.\")\n",
    "            try:\n",
    "                values_in_dict = values_dict[referred_item._id]\n",
    "                print(f\"...Found values {values_in_dict} to match to values set for {redef} ({redef._id})\")\n",
    "                try:\n",
    "                    values_dict[redef._id] = values_dict[redef._id] + values_in_dict\n",
    "                except KeyError:\n",
    "                    values_dict.update({redef._id: values_in_dict})\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        # also apply the value to redefined properties\n",
    "                \n",
    "    return values_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf1e40-20f3-4343-a02c-3daefd44916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_self_referencing_feature(feat, values_dict):\n",
    "    '''\n",
    "    Look to see if the feature is one of the special performance / occurrence features that includes at least the \n",
    "    featuring type itself. Examples include:\n",
    "    \n",
    "    self\n",
    "    timeEnclosedOccurrences\n",
    "    timeCoincidentOccurrences\n",
    "    spaceEnclosedOccurrences\n",
    "    spaceTimeEnclosedOccurrences\n",
    "    spaceTimeEnclosedPoints\n",
    "    spaceTimeCoincidentOccurrences\n",
    "    matingOccurrences - this one seems like an error\n",
    "    portions\n",
    "    portionOf\n",
    "    timeSlices\n",
    "    timeSliceOf\n",
    "    snapshots\n",
    "    startShot\n",
    "    endShot\n",
    "    spaceSlices\n",
    "    spaceSliceOf\n",
    "    dispatchScope\n",
    "    thisPerformance\n",
    "    '''\n",
    "    \n",
    "    self_referencers = [\n",
    "        \"self\",\n",
    "        \"sameLifeOccurrences\",\n",
    "        \"timeEnclosedOccurrences\",\n",
    "        \"timeCoincidentOccurrences\",\n",
    "        \"spaceEnclosedOccurrences\",\n",
    "        \"spaceTimeEnclosedOccurrences\",\n",
    "        \"spaceTimeEnclosedPoints\",\n",
    "        \"spaceTimeCoincidentOccurrences\",\n",
    "        \"matingOccurrences\",\n",
    "        \"portions\",\n",
    "        \"portionOf\",\n",
    "        \"timeSlices\",\n",
    "        \"timeSliceOf\",\n",
    "        \"snapshots\",\n",
    "        \"startShot\",\n",
    "        \"endShot\",\n",
    "        \"spaceSlices\",\n",
    "        \"spaceSliceOf\",\n",
    "        \"spaceShots\",\n",
    "        \"dispatchScope\",\n",
    "        \"thisPerformance\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"Checking to see if {feat.basic_name} matches self referencer list\")\n",
    "    \n",
    "    if feat.basic_name in self_referencers:\n",
    "        print(f\"Feature {feat} is a self-referencing Feature. Skipping until implementation is figured out.\")\n",
    "        print(f\"Feature parent is {feat.reverseFeatureMembership}\")\n",
    "        for rfm in feat.reverseFeatureMembership:\n",
    "            if rfm in values_dict:\n",
    "                print(f\"Value to match is {values_dict[rfm]}\")\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476dd20-1f30-48ec-9fd4-bfd3fdaefa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values_dictionary(model, values_dict):\n",
    "    print_string = \"\"\n",
    "    for k, v in values_dict.items():\n",
    "        print_string = print_string + f\">>>Key {model.get_element(k)} ({k}) has values {v}\\n\"\n",
    "        \n",
    "    print(print_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6013a68-fb3d-4304-ade0-9ee35b9b494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_values_in_model_atom_classifier_style(\n",
    "    input_model,\n",
    "    bound_features_to_atom_values_dict,\n",
    "    type_to_value,\n",
    "    new_classifier,\n",
    "    package_to_populate\n",
    "):\n",
    "\n",
    "    for bound_feature_id in bound_features_to_atom_values_dict.keys():\n",
    "        bound_feature = input_model.get_element(element_id=bound_feature_id)\n",
    "        if bound_feature._metatype in feature_metas():\n",
    "            print(f\"(Atom style)...Working to connect the feature {bound_feature} to generated types inside atom {new_classifier} via \" + \\\n",
    "                  f\"covering pattern with values {bound_features_to_atom_values_dict[bound_feature_id]}.\")\n",
    "            if type_to_value in bound_feature.reverseFeatureMembership:\n",
    "                redefined_bound_feature = apply_covered_feature_pattern(\n",
    "                    one_member_classifiers=bound_features_to_atom_values_dict[bound_feature_id],\n",
    "                    feature_to_cover=bound_feature,\n",
    "                    type_to_apply_pattern_on=new_classifier,\n",
    "                    model=input_model,\n",
    "                    new_types_owner=package_to_populate,\n",
    "                    covering_classifier_prefix=\"Values for \",\n",
    "                    covering_classifier_suffix=\"\",\n",
    "                    redefining_feature_prefix=\"\",\n",
    "                    redefining_feature_suffix=\" (Covered)\",\n",
    "                )\n",
    "        if bound_feature._metatype in connector_metas():\n",
    "            print(f\"(Atom style)...Working to connect the feature {bound_feature} to generated types inside atom {new_classifier} via \" + \\\n",
    "                  f\"covering pattern with values {bound_features_to_atom_values_dict[bound_feature_id]}.\")\n",
    "            print(f\"...Building covered connector under {new_classifier}\")\n",
    "                    \n",
    "            redefined_bound_feature = apply_covered_connector_pattern(\n",
    "                one_member_classifiers=bound_features_to_atom_values_dict[bound_feature_id],\n",
    "                feature_to_cover=bound_feature,\n",
    "                type_to_apply_pattern_on=new_classifier,\n",
    "                model=input_model,\n",
    "                new_types_owner=package_to_populate,\n",
    "                covering_classifier_prefix=\"Values for \",\n",
    "                covering_classifier_suffix=\"\",\n",
    "                redefining_feature_prefix=\"\",\n",
    "                redefining_feature_suffix=\"\",\n",
    "                metatype=bound_feature._metatype,\n",
    "                separate_connectors=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d591ff5-38ad-4426-9c02-275514111cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_write_performance_atoms(input_model,\n",
    "                                            bound_features_to_atom_values_dict,\n",
    "                                            cf_fwp,\n",
    "                                            package_to_populate):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create FeatureWritePerformance atoms and the associated timeslices\n",
    "    \"\"\"\n",
    "    \n",
    "    # find onOccurrence in feature list\n",
    "    \n",
    "    features_in_fwp = cf_fwp.feature\n",
    "    occurrence_bound = None\n",
    "    accessed_type = None\n",
    "    \n",
    "    print(f\"...Features found in FWP are {features_in_fwp}\")\n",
    "    \n",
    "    for cf in features_in_fwp:\n",
    "        if cf.basic_name == 'onOccurrence' and len(cf.throughRedefinition) > 0:\n",
    "            print(f\"...Found onOccurrence feature\")\n",
    "            occurrence_bound = get_feature_bound_values(cf)[0]\n",
    "            print(f\"...Found a feature value bound to onOccurrence feature which is {occurrence_bound}\")\n",
    "                    \n",
    "            # expect that onOccurrence has nested features\n",
    "            \n",
    "            for cf2 in cf.feature:\n",
    "                print(f\"...Features found in onOccurrence are {cf.feature}\")\n",
    "                if cf2.basic_name == 'startingAt' and len(cf.throughRedefinition) > 0:\n",
    "                    for cf3 in cf2.feature:\n",
    "                        if cf3.basic_name == 'accessedFeature' and len(cf.throughRedefinition) > 0:\n",
    "                            accessed_type = cf3.throughSubsetting[0]\n",
    "                            print(f\"...Found accessedFeature feature bound to {accessed_type}\")\n",
    "    \n",
    "    # get the thing to timeslice\n",
    "    \n",
    "    time_sliced_occurrence = None\n",
    "    \n",
    "    try:\n",
    "        time_sliced_occurrence = bound_features_to_atom_values_dict[occurrence_bound._id]\n",
    "        print(f\"...Occurrence atom for {occurrence_bound} is found as {time_sliced_occurrence}\")\n",
    "    except KeyError:\n",
    "        # need to make a new classifier here\n",
    "        print(f\"...No occurrence atom for {occurrence_bound} found. Creating a new one.\")\n",
    "        type_to_value = get_most_specific_feature_type(occurrence_bound)\n",
    "        base_name = type_to_value.basic_name\n",
    "        new_classifier = build_from_classifier_pattern(\n",
    "            owner=package_to_populate,\n",
    "            name=f\"My{base_name}\",\n",
    "            model=input_model,\n",
    "            specific_fields={},\n",
    "            metatype=type_to_value._metatype,\n",
    "            superclasses=[type_to_value]\n",
    "        )\n",
    "        time_sliced_occurrence = new_classifier\n",
    "        bound_features_to_atom_values_dict.update({occurrence_bound._id: [time_sliced_occurrence]})\n",
    "    \n",
    "    # create time slice for after this FWP is applied\n",
    "    \n",
    "    time_slice = None\n",
    "    need_new_slice = True\n",
    "    \n",
    "    try:\n",
    "        potential_atoms = package_to_populate.throughOwningMembership\n",
    "        occurrence_atoms = bound_features_to_atom_values_dict[occurrence_bound._id]\n",
    "        for pa in potential_atoms:\n",
    "            if pa.basic_name == get_most_specific_feature_type(occurrence_bound).basic_name + \"TimeSlice\":\n",
    "                print(f\"Found previous time slice created for {time_sliced_occurrence}\")\n",
    "                need_new_slice = False\n",
    "                time_slice = pa\n",
    "    except KeyError:\n",
    "        need_new_slice = True\n",
    "    \n",
    "    if need_new_slice:\n",
    "        new_slice = build_from_portion_pattern(\n",
    "            owner=package_to_populate,\n",
    "            name_extension=\"TimeSlice\",\n",
    "            model=input_model,\n",
    "            classifier_to_be_portioned=get_most_specific_feature_type(occurrence_bound),\n",
    "            feature_to_be_set=[],\n",
    "            feature_values=[],\n",
    "            specific_fields={}\n",
    "        )\n",
    "        time_slice = new_slice\n",
    "        #try:\n",
    "        #    bound_features_to_atom_values_dict[occurrence_bound._id].append(new_slice)\n",
    "        #except KeyError:\n",
    "        #    bound_features_to_atom_values_dict.update({occurrence_bound._id: [new_slice]})\n",
    "    \n",
    "    # need to add time slice to this occurrence\n",
    "    \n",
    "    print(f\"Building feature with metatype {cf_fwp._metatype} under {time_sliced_occurrence[0]} with name after{cf_fwp.basic_name.capitalize()}\")\n",
    "    \n",
    "    build_from_feature_pattern(\n",
    "        owner=time_sliced_occurrence[0],\n",
    "        name=\"after\"+cf_fwp.basic_name.capitalize(),\n",
    "        model=input_model,\n",
    "        specific_fields={},\n",
    "        feature_type=time_slice,\n",
    "        direction=\"\",\n",
    "        metatype=\"Feature\",\n",
    "        connector_end=False,\n",
    "    )\n",
    "    \n",
    "    type_to_value = get_most_specific_feature_type(cf_fwp)\n",
    "    base_name = cf_fwp.basic_name\n",
    "    fwp_atom = build_from_classifier_pattern(\n",
    "            owner=package_to_populate,\n",
    "            name=f\"FeatureWritePerformanceFor{base_name.capitalize()}\",\n",
    "            model=input_model,\n",
    "            specific_fields={},\n",
    "            metatype=type_to_value._metatype,\n",
    "            superclasses=[type_to_value]\n",
    "        )\n",
    "    \n",
    "    bound_features_to_atom_values_dict.update({cf_fwp._id: [fwp_atom]})\n",
    "    \n",
    "    return bound_features_to_atom_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a2ee2-694f-422f-a35c-71a3375d4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_values_for_type_annex_a(input_model,\n",
    "                                     package_to_execute,\n",
    "                                     package_to_populate,\n",
    "                                     type_to_value,\n",
    "                                     atom_index,\n",
    "                                     bound_features_to_atom_values_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate values for the given single type using the Annex A rules\n",
    "    \n",
    "    bound_features_to_atom_values_dict - pass as a mutable object, update as we go\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Applying Annex A atom algorithm to {type_to_value.basic_name}\")\n",
    "    \n",
    "    new_classifier = None\n",
    "    \n",
    "    # TODO: Create map from new_classifier to the features discovered under this type rather than having the dictionary key to features globally\n",
    "    \n",
    "    if type_to_value._metatype in classifier_metas() and not has_type_named(type_to_value, \"FeatureWritePerformance\"):\n",
    "    \n",
    "        # Step 1 - create new atom from the classifier\n",
    "        base_name = type_to_value.basic_name\n",
    "        new_classifier = build_from_classifier_pattern(\n",
    "            owner=package_to_populate,\n",
    "            name=f\"My{base_name}\",\n",
    "            model=input_model,\n",
    "            specific_fields={},\n",
    "            metatype=type_to_value._metatype,\n",
    "            superclasses=[type_to_value]\n",
    "        )\n",
    "        \n",
    "        print(f\"Executing step 1. Working from {base_name} to create {new_classifier}\")\n",
    "    \n",
    "    # use derived property 'feature' to get all features including the inherited ones\n",
    "    candidate_features = type_to_value.feature\n",
    "    \n",
    "    try:\n",
    "        #print(f\"Trying to find metatype for {type_to_value.throughFeatureTyping}\")\n",
    "        featured_meta = type_to_value.throughFeatureTyping[0]._metatype\n",
    "        print(f\"Type {type_to_value.basic_name} is has a type of metatype {featured_meta}.\")\n",
    "        if featured_meta in datatype_metas():\n",
    "            print(f\"Type {type_to_value.basic_name} is typed by a datatype. Bypassing further elaboration.\")\n",
    "            return bound_features_to_atom_values_dict\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f\"...Found features {candidate_features} under the type to value {type_to_value.basic_name}.\")\n",
    "    \n",
    "    # set up for multiple passes on the feature list, will test per pass to determine whether to handle it\n",
    "    \n",
    "    # TODO: Instead of this testing approach, gather all features and allocated into sub-collections that\n",
    "    # handle these passes\n",
    "    \n",
    "    passes = ['Non-connector Features', 'FeatureWritePerformances', 'Connector Features']\n",
    "    \n",
    "    for pass_number, pass_kind in enumerate(passes):\n",
    "        \n",
    "        print(f\"Currently on pass {pass_kind} under {type_to_value}.\")\n",
    "        print(f\"Current values dict at this step is\")\n",
    "        print_values_dictionary(input_model, bound_features_to_atom_values_dict)\n",
    "    \n",
    "        for cf in candidate_features:\n",
    "            \n",
    "            if has_type_named(cf, \"FeatureWritePerformance\") and not pass_kind == 'FeatureWritePerformances':\n",
    "                continue\n",
    "            if cf._metatype not in connector_metas() and not pass_kind == 'Non-connector Features':\n",
    "                if not has_type_named(cf, \"FeatureWritePerformance\"):\n",
    "                    continue\n",
    "            if cf._metatype in connector_metas() and not pass_kind == 'Connector Features':\n",
    "                continue\n",
    "            \n",
    "            # common pre-processing steps\n",
    "            \n",
    "            cf_name = cf.basic_name\n",
    "            \n",
    "            lm = get_effective_lower_multiplicity(cf)\n",
    "            \n",
    "            if lm > -1:\n",
    "                # need to test multiplicity\n",
    "                print(f\"...Found effective lower multiplicity of {cf_name} ({cf._id}) as {lm}.\")\n",
    "            elif cf._metatype not in connector_metas():\n",
    "                print(f\"...{cf_name} ({cf._id}) has unbounded multiplicity. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            redefining_features = set(cf.reverseRedefinition)\n",
    "            cf_redefined = False\n",
    "            \n",
    "            for rf in redefining_features:\n",
    "                print(f\"...Discovered that {cf} ({cf._id}) is redefined by {rf} ({rf._id})! Skipping.\")\n",
    "                cf_redefined = True\n",
    "                \n",
    "            if cf_redefined:\n",
    "                continue\n",
    "            \n",
    "            # Step 2 - find Features with lower multiplicity > 0 that are not connectors\n",
    "            \n",
    "            # Look for existing values for the feature or previous atom assignment\n",
    "            \n",
    "            values_set_in_model = find_model_existing_values_for_feature(cf, bound_features_to_atom_values_dict)\n",
    "            \n",
    "            # Pass-specific core steps\n",
    "            \n",
    "            if has_type_named(cf, \"FeatureWritePerformance\"):\n",
    "                print(f\"Feature {cf} has type of FeatureWritePerformance\")\n",
    "                if pass_kind == 'FeatureWritePerformances':\n",
    "                    create_feature_write_performance_atoms(\n",
    "                        input_model,\n",
    "                        bound_features_to_atom_values_dict,\n",
    "                        cf,\n",
    "                        package_to_populate\n",
    "                    )\n",
    "            \n",
    "            elif cf._metatype not in connector_metas() and pass_kind == 'Non-connector Features':\n",
    "                \n",
    "                handled_as_self_reference = handle_self_referencing_feature(cf, bound_features_to_atom_values_dict)\n",
    "                \n",
    "                if len(values_set_in_model) == 0 and handled_as_self_reference == False:\n",
    "                    # Step 3 - create new Atoms to go with the Features\n",
    "                    \n",
    "                    used_typ = get_most_specific_feature_type(cf)\n",
    "                    \n",
    "                    if used_typ._metatype in datatype_metas():\n",
    "                        print(f\"Executing step 2. Identified {cf_name} ({cf._id}) as a non-connector Feature. No existing values found. \" + \\\n",
    "                              f\"This is a datatype. Skipping generation of values.\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"Executing step 2. Identified {cf_name} ({cf._id}) as a non-connector Feature. No existing values found. \" + \\\n",
    "                              f\"Generating {lm} new values specializing type {used_typ}.\")\n",
    "                    \n",
    "                    for i in range(0, lm):\n",
    "                        inspect_type_for_atom_rev_2(input_model,\n",
    "                          package_to_execute,\n",
    "                          package_to_populate,\n",
    "                          i,\n",
    "                          cf,\n",
    "                          used_typ,\n",
    "                          bound_features_to_atom_values_dict\n",
    "                         )\n",
    "                                \n",
    "            if cf._metatype in connector_metas() and pass_kind == 'Connector Features':\n",
    "                print(f\"Executing step 4. Identified {cf.basic_name} as a Connector\")\n",
    "\n",
    "                # check the feature ends of the connector\n",
    "                \n",
    "                used_typ = get_most_specific_feature_type(cf)\n",
    "                \n",
    "                connector_atoms = []\n",
    "\n",
    "                connector_ends = cf.throughEndFeatureMembership\n",
    "\n",
    "                lm_end1 = get_effective_lower_multiplicity(connector_ends[0])\n",
    "                lm_end2 = get_effective_lower_multiplicity(connector_ends[1])\n",
    "\n",
    "                if lm_end1 == 1 and lm_end2 == 1:\n",
    "                    print(f\"Executing step 5. Identified {cf} as a Connector with 1-to-1 ends\")\n",
    "                    \n",
    "                    end_connected_mults = [get_effective_lower_multiplicity(connector_ends[i].throughReferenceSubsetting[0]) for i in range(0,2)]\n",
    "                    \n",
    "                    # get the multiplicity of the ends\n",
    "                    #end1_connected_mult = get_effective_lower_multiplicity(connector_ends[0].throughReferenceSubsetting[0])\n",
    "                    #end2_connected_mult = get_effective_lower_multiplicity(connector_ends[1].throughReferenceSubsetting[0])\n",
    "                    \n",
    "                    for i, end_connected_mult in enumerate(end_connected_mults):\n",
    "                    \n",
    "                        print(f\"...Effective lower multiplicity of {connector_ends[i].throughReferenceSubsetting[0]}, bound to assoc feature {connector_ends[i]}, \" + \\\n",
    "                              f\"is {end_connected_mult}\")\n",
    "\n",
    "                    # check to see if the already built instances have a finite value\n",
    "                    \n",
    "                    print(f\"...Looking for connected end feature values filled in during execution.\")\n",
    "                    \n",
    "                    found_values = []\n",
    "                    \n",
    "                    ends_to_process = []\n",
    "\n",
    "                    if hasattr(cf, \"throughEndFeatureMembership\"):\n",
    "                        for cf_ele in cf.throughEndFeatureMembership:\n",
    "                            ends_to_process.append(cf_ele)\n",
    "                    if used_typ is not None and hasattr(used_typ, \"throughEndFeatureMembership\"):\n",
    "                        for cf_ele in used_typ.throughEndFeatureMembership:\n",
    "                            ends_to_process.append(cf_ele)\n",
    "                    \n",
    "                    for con_end in ends_to_process:\n",
    "                        bound_feature = con_end.throughReferenceSubsetting[0]\n",
    "                        if bound_feature._id in bound_features_to_atom_values_dict:\n",
    "                            print(f\"...Found connected end feature values filled in during execution {bound_features_to_atom_values_dict[bound_feature._id]}!\")\n",
    "                            found_values.append(len(bound_features_to_atom_values_dict[bound_feature._id]))\n",
    "                                                          \n",
    "                    number_to_make = max(end_connected_mults + found_values)\n",
    "                    \n",
    "                    print(f\"...Found that number of atoms to make for {cf} is {number_to_make}\")\n",
    "\n",
    "                    feature_value_atoms = []\n",
    "\n",
    "                    used_typ = None\n",
    "\n",
    "                    for i in range(0, number_to_make):\n",
    "                        print(f\"Executing step 5b. Creating atom #{i + 1} to be value for {cf}\")\n",
    "\n",
    "                        typ = []\n",
    "                        used_typ = None\n",
    "                        used_name = cf.basic_name\n",
    "                        used_metatype = \"Association\"\n",
    "                        \n",
    "                        elaboration_end = False\n",
    "\n",
    "                        if hasattr(cf, \"throughFeatureTyping\"):\n",
    "                            typ = cf.throughFeatureTyping\n",
    "\n",
    "                        if len(typ) > 0:\n",
    "                            used_typ = typ[0]\n",
    "                            used_name = used_typ.basic_name\n",
    "                            used_metatype = used_typ._metatype\n",
    "\n",
    "                        #feature_value_atoms.append(new_ft_classifier)\n",
    "\n",
    "                        # need to do this for Association types and also nested end features\n",
    "\n",
    "                        #ends_to_process = []\n",
    "\n",
    "                        #if hasattr(cf, \"throughEndFeatureMembership\"):\n",
    "                        #    for cf_ele in cf.throughEndFeatureMembership:\n",
    "                        #        ends_to_process.append(cf_ele)\n",
    "                        #if used_typ is not None and hasattr(used_typ, \"throughEndFeatureMembership\"):\n",
    "                        #    for cf_ele in used_typ.throughEndFeatureMembership:\n",
    "                        #        ends_to_process.append(cf_ele)\n",
    "\n",
    "                        for con_end in ends_to_process:\n",
    "                            print(f\"...Inspecting {con_end} for connected features.\")\n",
    "                            if len(con_end.throughReferenceSubsetting) > 0:\n",
    "                                bound_feature = con_end.throughReferenceSubsetting[0]\n",
    "                                bound_feature_type = bound_feature.throughFeatureTyping\n",
    "\n",
    "                                print(f\"...Found connected feature {bound_feature}.\")\n",
    "\n",
    "                                if len(bound_feature_type) > 0:\n",
    "                                    feature_used_type = bound_feature_type[0]\n",
    "\n",
    "                                    if bound_feature._id in bound_features_to_atom_values_dict:\n",
    "                                        # if not enough atoms exist, make some more\n",
    "                                        if (i + 1) > len(bound_features_to_atom_values_dict[bound_feature._id]):\n",
    "                                            print(f\"Executing step 5b (1-to-1 variant). Creating atom #{i + 1} to \" + \\\n",
    "                                                f\"be value for {con_end} and also {bound_feature} to fill in rest of values.\")\n",
    "                                            \n",
    "                                            inspect_type_for_atom_rev_2(input_model,\n",
    "                                                                      package_to_execute,\n",
    "                                                                      package_to_populate,\n",
    "                                                                      i,\n",
    "                                                                      bound_feature,\n",
    "                                                                      feature_used_type,\n",
    "                                                                      bound_features_to_atom_values_dict\n",
    "                                                                     )\n",
    "                                            \n",
    "                                    else:\n",
    "                                        print(f\"Executing step 5b (1-to-1 variant). Creating atom #{i + 1} to \" + \\\n",
    "                                            f\"be value for {con_end} and also {bound_feature}\")\n",
    "                                        \n",
    "                                        if has_type_named(bound_feature, \"FeatureWritePerformance\"):\n",
    "                                            create_feature_write_performance_atoms(\n",
    "                                                input_model,\n",
    "                                                bound_features_to_atom_values_dict,\n",
    "                                                bound_feature,\n",
    "                                                package_to_populate\n",
    "                                            )\n",
    "                                        \n",
    "                                        else:\n",
    "                                            inspect_type_for_atom_rev_2(input_model,\n",
    "                                                                      package_to_execute,\n",
    "                                                                      package_to_populate,\n",
    "                                                                      i,\n",
    "                                                                      bound_feature,\n",
    "                                                                      feature_used_type,\n",
    "                                                                      bound_features_to_atom_values_dict            \n",
    "                                                                     )\n",
    "                                        \n",
    "\n",
    "                        if len(ends_to_process) == 2:\n",
    "                            source_end = ends_to_process[0]\n",
    "                            target_end = ends_to_process[1]\n",
    "\n",
    "                            source_bound_feature = source_end.throughReferenceSubsetting[0]\n",
    "                            target_bound_feature = target_end.throughReferenceSubsetting[0]\n",
    "                            \n",
    "                            try:\n",
    "                                source_atom = bound_features_to_atom_values_dict[source_bound_feature._id][i]\n",
    "                            except KeyError:\n",
    "                                raise KeyError(f\"...Failed to find atoms for {source_bound_feature} and connector {cf}.\" + \\\n",
    "                                               f\"{bound_features_to_atom_values_dict}\")\n",
    "                            \n",
    "                            try:\n",
    "                                target_atom = bound_features_to_atom_values_dict[target_bound_feature._id][i]\n",
    "                            except KeyError:\n",
    "                                raise KeyError(f\"...Failed to find atoms for {target_bound_feature} and connector {cf}.\" + \\\n",
    "                                               f\"{bound_features_to_atom_values_dict}\")\n",
    "\n",
    "                            print(f\"...Typing atom association ends from {source_atom} to {target_atom} under \" + \n",
    "                                 f\"{used_name}{i + 1} to specialize {[ft.basic_name for ft in cf.throughFeatureTyping]}\")\n",
    "                            \n",
    "                            # check for typing\n",
    "                            \n",
    "                            cn_types = cf.throughFeatureTyping\n",
    "                            \n",
    "                            if len(cf.throughFeatureTyping) == 0:\n",
    "                                pass\n",
    "\n",
    "                            new_cn_classifier = build_from_binary_assoc_pattern(\n",
    "                                name=f\"{used_name}{i + 1}\",\n",
    "                                source_role_name=connector_ends[0].basic_name,\n",
    "                                target_role_name=connector_ends[1].basic_name,\n",
    "                                source_type=source_atom,\n",
    "                                target_type=target_atom,\n",
    "                                model=input_model,\n",
    "                                metatype=used_metatype,\n",
    "                                owner=package_to_populate,\n",
    "                                superclasses=cf.throughFeatureTyping,\n",
    "                                specific_fields={}\n",
    "                            )\n",
    "                            \n",
    "                            if cf._id in bound_features_to_atom_values_dict:\n",
    "                                bound_features_to_atom_values_dict[cf._id].append(new_cn_classifier)\n",
    "                            else:\n",
    "                                bound_features_to_atom_values_dict.update({cf._id: [new_cn_classifier]})\n",
    "                            \n",
    "                            connector_atoms.append(new_cn_classifier)\n",
    "                        \n",
    "            \n",
    "    #if type_to_value._metatype in feature_metas():\n",
    "        # Step 1 - create new atom from the classifier\n",
    "        \n",
    "    #    try:\n",
    "            #print(f\"Trying to find metatype for {type_to_value.throughFeatureTyping}\")\n",
    "    #        feature_type = get_most_specific_feature_type(type_to_value)\n",
    "            #feature_type = type_to_value.throughFeatureTyping[0]\n",
    "    #        print(f\"Found type {feature_type} for {type_to_value}.\")\n",
    "            \n",
    "    #        base_name = feature_type.basic_name\n",
    "    #        new_classifier = build_from_classifier_pattern(\n",
    "    #            owner=package_to_populate,\n",
    "    #            name=f\"My{base_name}\",\n",
    "    #            model=input_model,\n",
    "    #            specific_fields={},\n",
    "    #            metatype=type_to_value._metatype,\n",
    "    #            superclasses=[type_to_value]\n",
    "    #        )\n",
    "            \n",
    "    #        print(f\"Executing step 1. Working from {base_name} to create {new_classifier.declaredName}\") \n",
    "            \n",
    "    #    except:\n",
    "    #        print(f\"Cannot find the feature type for {type_to_value.basic_name}\")\n",
    "        \n",
    "    if type_to_value._metatype in datatype_metas():\n",
    "        print(f\"Classifier {type_to_value.basic_name} is a datatype. Bypassing further elaboration.\")\n",
    "        return bound_features_to_atom_values_dict\n",
    "    \n",
    "    elif get_most_specific_feature_type(type_to_value) is not None:\n",
    "        \n",
    "        try:\n",
    "            if get_most_specific_feature_type(type_to_value)._metatype in datatype_metas():\n",
    "                print(f\"Classifier {type_to_value.basic_name} is a datatype or typed by one. Bypassing further elaboration.\")\n",
    "                return bound_features_to_atom_values_dict\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    print(f\"Current values dict is\")\n",
    "    print_values_dictionary(input_model, bound_features_to_atom_values_dict)\n",
    "    \n",
    "    if len(bound_features_to_atom_values_dict.keys()) == 0:\n",
    "        return {}\n",
    "    \n",
    "    if new_classifier == None:\n",
    "        print(f\"...No classifiers created for {type_to_value}\")\n",
    "        try:\n",
    "            new_classifier = bound_features_to_atom_values_dict[type_to_value._id][atom_index]\n",
    "            print(f\"...Classifier for {type_to_value} found in bound values dict as {new_classifier}\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "    else:\n",
    "        print(f\"...Classifier {new_classifier} created for {type_to_value}\")\n",
    "    \n",
    "    embed_values_in_model_atom_classifier_style(\n",
    "        input_model,\n",
    "        bound_features_to_atom_values_dict,\n",
    "        type_to_value,\n",
    "        new_classifier,\n",
    "        package_to_populate\n",
    "    )\n",
    "    \n",
    "    return bound_features_to_atom_values_dict\n",
    "    \n",
    "    #print(f\"Bound features dict: \\n{bound_features_to_atom_values_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27e6cc-2fd8-4890-9c93-a7e8caa1c6ad",
   "metadata": {},
   "source": [
    "## Atom Metadata Load\n",
    "\n",
    "Bring up the Atom metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d104ea-d80a-4c73-ba7e-8bc96c942ce8",
   "metadata": {},
   "source": [
    "filename = \"A-2-Atoms\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "atoms_data = pm.Model.load_from_post_file(json_file)\n",
    "atoms_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42352a-0aa9-4e97-8959-f8fcd026b565",
   "metadata": {},
   "source": [
    "## Annex A.3.2 Without Connectors Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa3d32-7a9f-44b7-abb8-87fc45922128",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-2-WithoutConnectors\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "without_connectors_data = pm.Model.load_from_post_file(json_file)\n",
    "without_connectors_data\n",
    "\n",
    "without_connectors_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd842c-b348-4f13-9c68-6d6d45241d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in without_connectors_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573e8e8-a1fb-4589-8244-65514cbce1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_connectors_to_execute_classifiers = \\\n",
    "    [ele for ele in packages[0].throughOwningMembership if ele._metatype == 'Classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22680e9-33ef-465b-8bb1-76ffa110c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_connectors_executor = KermlForwardExecutor(without_connectors_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a359ea-5462-4f8f-8c0c-18115d80ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca76d4-f55e-4790-ad56-f3e14dd6d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughSubclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3a331-4359-4d3f-bb37-6fe88576baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[2].basic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97701325-d284-4bfe-b2b8-24451451a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_connectors_executor.execute_from_classifier(packages[0].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd51eb-66e8-4241-9abc-d7821f4885a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76527f48-4908-42a8-8115-f9895e2a00af",
   "metadata": {},
   "source": [
    "## Annex A.3.3 One-To-One Connectors Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fe8c2-aa35-45e1-aaa5-d63bf92f629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-3-OneToOneConnectors\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "one_2_one_connectors_data = pm.Model.load_from_post_file(json_file)\n",
    "one_2_one_connectors_data\n",
    "\n",
    "one_2_one_connectors_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5f94f-5db8-4df1-b528-947dcd45e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in one_2_one_connectors_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448824de-7223-4895-86bf-993497dbd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_2_one_connectors_executor = KermlForwardExecutor(one_2_one_connectors_data, packages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51301a43-d790-40b7-be39-33e55febea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[2].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2977955-e553-4c30-8a41-3d8899d219b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[2].throughOwningMembership[1].throughFeatureMembership[0].throughEndFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ce455-334c-44a5-b45e-2d82df1cfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_2_one_connectors_executor.execute_from_classifier(packages[2].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b0dfa-e4d7-4e37-951b-7a49b96e91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[3].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c40ea-1008-4010-aee4-08b53f767027",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[3].throughOwningMembership[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb2b94-e97e-46b9-912e-eb9b9d8eb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[3].throughOwningMembership[4].throughSubclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33368566-8042-4c8d-a2da-d7c70fd1bc7d",
   "metadata": {},
   "source": [
    "## Annex A.3.6 Timing for Behaviors, Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d5aba-7169-41ce-b47d-6c9dc1e35636",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-6-Sequences\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "sequences_data = pm.Model.load_from_post_file(json_file)\n",
    "sequences_data\n",
    "\n",
    "sequences_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736b5cd-3f6f-4a18-b390-1ecf26cd6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in sequences_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305e541-907d-4284-9ef2-7419d2355a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec0f7b-c7a4-4868-b7e2-151c7b9ee3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c528fe2-40d2-4338-96e1-b6312fabac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughFeatureMembership[0].throughSubsetting[0]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1fa26-79be-4aab-8a74-aa13268317c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_executor = KermlForwardExecutor(sequences_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ad882-269e-4fcc-92e6-cac35b2f2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_executor.execute_from_classifier(packages[0].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021673bf-e141-43b8-9239-d01c1a3d57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca1d1c-8ee3-41eb-b599-12fc0b718d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3180d0-f4ea-46df-8da6-0690a93d5617",
   "metadata": {},
   "source": [
    "## Annex A.3.8 Feature Value Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e873c4-53b3-4d5e-aa73-762461422aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-8-ChangingFeatureValues\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "values_data = pm.Model.load_from_post_file(json_file)\n",
    "values_data\n",
    "\n",
    "values_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc51fc-9e1a-4941-9b69-57a8419a9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in values_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411f9d6-1ab7-47aa-a4dd-9b4341cfcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02552818-d6a3-45d5-8027-0fd7767c71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_executor = KermlForwardExecutor(values_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a737f-5f49-4c9d-8f57-e02e6e2d97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20baf9e8-6cfc-4b76-8b24-bcfdec606836",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_type_named(packages[0].throughOwningMembership[3].throughFeatureMembership[1], \"FeatureWritePerformance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd72ec-20da-4d43-8081-2a9802014ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[1].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7e028-f710-403f-9c6e-4f464fb7bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[1].throughFeatureMembership[0].throughFeatureMembership[0].throughFeatureMembership[0].throughSubsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf834ac-42b4-46f5-8e47-bde726074fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_executor.execute_from_classifier(packages[0].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579d9df-eb4d-4766-8980-31ca82927450",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ffce2-eba0-47b3-b5f2-5721783f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c11352-fd73-4918-ae7c-1d408c42b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9902f87-dcf6-44da-a868-949db072a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24319a-617a-4548-8170-6351b9ec24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120a0fe-feee-4d08-b95f-bce2e70d6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c7cac-9991-4b2e-8a12-bb637bc47e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughParameterMembership[0].throughFeatureValue[0].throughMembership[0].basic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f35260-82e4-444d-9339-06c952ee2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0]\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d4fc-0e55-4368-a3e9-54776eb0e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first item will be FRE to another feature\n",
    "expression_label = (\n",
    "    expression.throughParameterMembership[0]\n",
    "    .throughFeatureValue[0]\n",
    "    .throughMembership[0]\n",
    "    .basic_name\n",
    ")\n",
    "# check if this is a two-item feature chain or n > 2\n",
    "if \"throughMembership\" in expression._derived and len(expression.throughMembership) > 0:\n",
    "    # if hasattr(expression, \"throughMembership\"):\n",
    "    # this is the n = 2 case\n",
    "    second_item = expression.throughMembership[0].basic_name\n",
    "    expression_label += f\".{second_item}\"\n",
    "else:\n",
    "    # this is the n > 2 case\n",
    "    chains = expression.throughOwningMembership[0].throughFeatureChaining\n",
    "    other_items = \".\".join([chain.basic_name for chain in chains])\n",
    "    expression_label += f\".{other_items}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31860f0c-9c9f-40e9-bc31-fea93dd6fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07727d33-db29-4ba9-8cd7-3cfbaae471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughOwningMembership[0].throughFeatureChaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ed49e-9773-4aba-8870-c4cbb09011f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04353254-2f0f-4802-a155-46ad121d0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151fb4d-5bac-454a-a933-7038d4db2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157455b-c51a-4c40-a2d4-7ac53a8a7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_data._add_labels(packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14fcfc-1561-4df4-81ad-f049d0695d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypaint1 = get_more_general_types(packages[1].throughOwningMembership[2],0,100)\n",
    "mypaint1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c56014-5eae-4043-bfb5-9a6c7748278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypaint1[1]._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cf6ef-42e3-4689-b714-063fc14589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "derive_inherited_featurememberships(packages[0].throughOwningMembership[3].throughFeatureMembership[0].throughFeatureTyping[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bbd1d-dc9b-4344-a9af-8f50e87a0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[0].throughFeatureTyping[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73f78a-585c-4c8c-9523-eb7fe3907d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
