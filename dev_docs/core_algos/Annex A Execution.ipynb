{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b29b3fe-4145-499c-90f9-a383a8d3ca02",
   "metadata": {},
   "source": [
    "# Annex A Execution\n",
    "\n",
    "A notebook implementing the execution rules from KerML Annex A with PyMBE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7839ebb-7c5b-4284-9ca4-5a83c53cb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymbe.api as pm\n",
    "\n",
    "import copy\n",
    "\n",
    "from importlib import resources as lib_resources\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Any, Collection, Dict, List, Tuple, Union\n",
    "\n",
    "from pymbe.model import Model, Element\n",
    "from pymbe.model_modification import *\n",
    "\n",
    "from pymbe.query.metamodel_navigator import is_type_undefined_mult, \\\n",
    "                                    is_multiplicity_one, \\\n",
    "                                    is_multiplicity_specific_finite, \\\n",
    "                                    get_finite_multiplicity_types, \\\n",
    "                                    identify_connectors_one_side, \\\n",
    "                                    get_lower_multiplicity, \\\n",
    "                                    get_upper_multiplicity, \\\n",
    "                                    does_behavior_have_write_features, \\\n",
    "                                    get_most_specific_feature_type, \\\n",
    "                                    has_type_named, \\\n",
    "                                    get_effective_lower_multiplicity, \\\n",
    "                                    get_feature_bound_values, \\\n",
    "                                    get_more_general_types\n",
    "\n",
    "from pymbe.metamodel import derive_inherited_featurememberships\n",
    "\n",
    "from pymbe.text_concrete_syntax import serialize_kerml_atom\n",
    "\n",
    "from pymbe.interpretation.working_maps import FeatureTypeWorkingMap\n",
    "from pymbe.interpretation.execute_kerml_atoms import KermlForwardExecutor\n",
    "\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58774846-db97-4e49-b8da-6eef42b2b0b0",
   "metadata": {},
   "source": [
    "## Key Helpers for the Algorithm\n",
    "\n",
    "These helpers are yet to be implemented in the core of the Python tool and thus need to be more spelled out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c53c5-b093-45b3-8026-2cea43082b3d",
   "metadata": {},
   "source": [
    "### Check for Connectors to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b787a36-0513-48b7-bf60-3793ccc30c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_feature_connected(feature):\n",
    "    print(f\"...Inspecting {feature.declaredName} for connector references.\")\n",
    "    if hasattr(feature, \"reverseReferenceSubsetting\"):\n",
    "        print(f\"...Found link to connector end {feature.reverseReferenceSubsetting[0]}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"...Found no reverse edge outgoing to connector end.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caea0ba-ebf3-473e-93d6-f4f02037ab92",
   "metadata": {},
   "source": [
    "# Load up Kernel Libraries\n",
    "\n",
    "Load up the model libraries into memory so that key features for subsetting can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9067b-6355-4b9d-9ef4-46cbdb353ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = \"KernelLibrary\"\n",
    "\n",
    "library_model = None\n",
    "\n",
    "with lib_resources.path(\"pymbe.static_data\", \"KernelLibrary.json\") as lib_data:\n",
    "    library_model = pm.Model.load_from_post_file(lib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf018c2-6bb6-49a4-9358-02ba6a991b13",
   "metadata": {},
   "source": [
    "## Routines for Execution\n",
    "\n",
    "The following sections are focused on solving the problem of mapping values to KerML types in the model. The approach taken here is to find one legal set of values for types in the model via an approach where the program will walk straight ahead in the model, deriving values as it goes. This approach is called \"execution\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476dd20-1f30-48ec-9fd4-bfd3fdaefa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values_dictionary(model, values_dict):\n",
    "    print_string = \"\"\n",
    "    for k, v in values_dict.items():\n",
    "        print_string = print_string + f\">>>Key {model.get_element(k)} ({k}) has values {v}\\n\"\n",
    "        \n",
    "    print(print_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a2ee2-694f-422f-a35c-71a3375d4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_values_for_type_annex_a(input_model,\n",
    "                                     package_to_execute,\n",
    "                                     package_to_populate,\n",
    "                                     type_to_value,\n",
    "                                     atom_index,\n",
    "                                     bound_features_to_atom_values_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate values for the given single type using the Annex A rules\n",
    "    \n",
    "    bound_features_to_atom_values_dict - pass as a mutable object, update as we go\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Applying Annex A atom algorithm to {type_to_value.basic_name}\")\n",
    "    \n",
    "    new_classifier = None\n",
    "    \n",
    "    # TODO: Create map from new_classifier to the features discovered under this type rather than having the dictionary key to features globally\n",
    "    \n",
    "    if type_to_value._metatype in classifier_metas() and not has_type_named(type_to_value, \"FeatureWritePerformance\"):\n",
    "    \n",
    "        # Step 1 - create new atom from the classifier\n",
    "        base_name = type_to_value.basic_name\n",
    "        new_classifier = build_from_classifier_pattern(\n",
    "            owner=package_to_populate,\n",
    "            name=f\"My{base_name}\",\n",
    "            model=input_model,\n",
    "            specific_fields={},\n",
    "            metatype=type_to_value._metatype,\n",
    "            superclasses=[type_to_value]\n",
    "        )\n",
    "        \n",
    "        print(f\"Executing step 1. Working from {base_name} to create {new_classifier}\")\n",
    "    \n",
    "    # use derived property 'feature' to get all features including the inherited ones\n",
    "    candidate_features = type_to_value.feature\n",
    "    \n",
    "    try:\n",
    "        #print(f\"Trying to find metatype for {type_to_value.throughFeatureTyping}\")\n",
    "        featured_meta = type_to_value.throughFeatureTyping[0]._metatype\n",
    "        print(f\"Type {type_to_value.basic_name} is has a type of metatype {featured_meta}.\")\n",
    "        if featured_meta in datatype_metas():\n",
    "            print(f\"Type {type_to_value.basic_name} is typed by a datatype. Bypassing further elaboration.\")\n",
    "            return bound_features_to_atom_values_dict\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f\"...Found features {candidate_features} under the type to value {type_to_value.basic_name}.\")\n",
    "    \n",
    "    # set up for multiple passes on the feature list, will test per pass to determine whether to handle it\n",
    "    \n",
    "    # TODO: Instead of this testing approach, gather all features and allocated into sub-collections that\n",
    "    # handle these passes\n",
    "    \n",
    "    passes = ['Non-connector Features', 'FeatureWritePerformances', 'Connector Features']\n",
    "    \n",
    "    for pass_number, pass_kind in enumerate(passes):\n",
    "        \n",
    "        print(f\"Currently on pass {pass_kind} under {type_to_value}.\")\n",
    "        print(f\"Current values dict at this step is\")\n",
    "        print_values_dictionary(input_model, bound_features_to_atom_values_dict)\n",
    "    \n",
    "        for cf in candidate_features:\n",
    "            \n",
    "            if has_type_named(cf, \"FeatureWritePerformance\") and not pass_kind == 'FeatureWritePerformances':\n",
    "                continue\n",
    "            if cf._metatype not in connector_metas() and not pass_kind == 'Non-connector Features':\n",
    "                if not has_type_named(cf, \"FeatureWritePerformance\"):\n",
    "                    continue\n",
    "            if cf._metatype in connector_metas() and not pass_kind == 'Connector Features':\n",
    "                continue\n",
    "            \n",
    "            # common pre-processing steps\n",
    "            \n",
    "            cf_name = cf.basic_name\n",
    "            \n",
    "            lm = get_effective_lower_multiplicity(cf)\n",
    "            \n",
    "            if lm > -1:\n",
    "                # need to test multiplicity\n",
    "                print(f\"...Found effective lower multiplicity of {cf_name} ({cf._id}) as {lm}.\")\n",
    "            elif cf._metatype not in connector_metas():\n",
    "                print(f\"...{cf_name} ({cf._id}) has unbounded multiplicity. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            redefining_features = set(cf.reverseRedefinition)\n",
    "            cf_redefined = False\n",
    "            \n",
    "            for rf in redefining_features:\n",
    "                print(f\"...Discovered that {cf} ({cf._id}) is redefined by {rf} ({rf._id})! Skipping.\")\n",
    "                cf_redefined = True\n",
    "                \n",
    "            if cf_redefined:\n",
    "                continue\n",
    "            \n",
    "            # Step 2 - find Features with lower multiplicity > 0 that are not connectors\n",
    "            \n",
    "            # Look for existing values for the feature or previous atom assignment\n",
    "            \n",
    "            values_set_in_model = find_model_existing_values_for_feature(cf, bound_features_to_atom_values_dict)\n",
    "            \n",
    "            # Pass-specific core steps\n",
    "            \n",
    "            if has_type_named(cf, \"FeatureWritePerformance\"):\n",
    "                print(f\"Feature {cf} has type of FeatureWritePerformance\")\n",
    "                if pass_kind == 'FeatureWritePerformances':\n",
    "                    create_feature_write_performance_atoms(\n",
    "                        input_model,\n",
    "                        bound_features_to_atom_values_dict,\n",
    "                        cf,\n",
    "                        package_to_populate\n",
    "                    )\n",
    "            \n",
    "            elif cf._metatype not in connector_metas() and pass_kind == 'Non-connector Features':\n",
    "                \n",
    "                handled_as_self_reference = handle_self_referencing_feature(cf, bound_features_to_atom_values_dict)\n",
    "                \n",
    "                if len(values_set_in_model) == 0 and handled_as_self_reference == False:\n",
    "                    # Step 3 - create new Atoms to go with the Features\n",
    "                    \n",
    "                    used_typ = get_most_specific_feature_type(cf)\n",
    "                    \n",
    "                    if used_typ._metatype in datatype_metas():\n",
    "                        print(f\"Executing step 2. Identified {cf_name} ({cf._id}) as a non-connector Feature. No existing values found. \" + \\\n",
    "                              f\"This is a datatype. Skipping generation of values.\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"Executing step 2. Identified {cf_name} ({cf._id}) as a non-connector Feature. No existing values found. \" + \\\n",
    "                              f\"Generating {lm} new values specializing type {used_typ}.\")\n",
    "                    \n",
    "                    for i in range(0, lm):\n",
    "                        inspect_type_for_atom_rev_2(input_model,\n",
    "                          package_to_execute,\n",
    "                          package_to_populate,\n",
    "                          i,\n",
    "                          cf,\n",
    "                          used_typ,\n",
    "                          bound_features_to_atom_values_dict\n",
    "                         )\n",
    "                                \n",
    "            if cf._metatype in connector_metas() and pass_kind == 'Connector Features':\n",
    "                print(f\"Executing step 4. Identified {cf.basic_name} as a Connector\")\n",
    "\n",
    "                # check the feature ends of the connector\n",
    "                \n",
    "                used_typ = get_most_specific_feature_type(cf)\n",
    "                \n",
    "                connector_atoms = []\n",
    "\n",
    "                connector_ends = cf.throughEndFeatureMembership\n",
    "\n",
    "                lm_end1 = get_effective_lower_multiplicity(connector_ends[0])\n",
    "                lm_end2 = get_effective_lower_multiplicity(connector_ends[1])\n",
    "\n",
    "                if lm_end1 == 1 and lm_end2 == 1:\n",
    "                    print(f\"Executing step 5. Identified {cf} as a Connector with 1-to-1 ends\")\n",
    "                    \n",
    "                    end_connected_mults = [get_effective_lower_multiplicity(connector_ends[i].throughReferenceSubsetting[0]) for i in range(0,2)]\n",
    "                    \n",
    "                    # get the multiplicity of the ends\n",
    "                    #end1_connected_mult = get_effective_lower_multiplicity(connector_ends[0].throughReferenceSubsetting[0])\n",
    "                    #end2_connected_mult = get_effective_lower_multiplicity(connector_ends[1].throughReferenceSubsetting[0])\n",
    "                    \n",
    "                    for i, end_connected_mult in enumerate(end_connected_mults):\n",
    "                    \n",
    "                        print(f\"...Effective lower multiplicity of {connector_ends[i].throughReferenceSubsetting[0]}, bound to assoc feature {connector_ends[i]}, \" + \\\n",
    "                              f\"is {end_connected_mult}\")\n",
    "\n",
    "                    # check to see if the already built instances have a finite value\n",
    "                    \n",
    "                    print(f\"...Looking for connected end feature values filled in during execution.\")\n",
    "                    \n",
    "                    found_values = []\n",
    "                    \n",
    "                    ends_to_process = []\n",
    "\n",
    "                    if hasattr(cf, \"throughEndFeatureMembership\"):\n",
    "                        for cf_ele in cf.throughEndFeatureMembership:\n",
    "                            ends_to_process.append(cf_ele)\n",
    "                    if used_typ is not None and hasattr(used_typ, \"throughEndFeatureMembership\"):\n",
    "                        for cf_ele in used_typ.throughEndFeatureMembership:\n",
    "                            ends_to_process.append(cf_ele)\n",
    "                    \n",
    "                    for con_end in ends_to_process:\n",
    "                        bound_feature = con_end.throughReferenceSubsetting[0]\n",
    "                        if bound_feature._id in bound_features_to_atom_values_dict:\n",
    "                            print(f\"...Found connected end feature values filled in during execution {bound_features_to_atom_values_dict[bound_feature._id]}!\")\n",
    "                            found_values.append(len(bound_features_to_atom_values_dict[bound_feature._id]))\n",
    "                                                          \n",
    "                    number_to_make = max(end_connected_mults + found_values)\n",
    "                    \n",
    "                    print(f\"...Found that number of atoms to make for {cf} is {number_to_make}\")\n",
    "\n",
    "                    feature_value_atoms = []\n",
    "\n",
    "                    used_typ = None\n",
    "\n",
    "                    for i in range(0, number_to_make):\n",
    "                        print(f\"Executing step 5b. Creating atom #{i + 1} to be value for {cf}\")\n",
    "\n",
    "                        typ = []\n",
    "                        used_typ = None\n",
    "                        used_name = cf.basic_name\n",
    "                        used_metatype = \"Association\"\n",
    "                        \n",
    "                        elaboration_end = False\n",
    "\n",
    "                        if hasattr(cf, \"throughFeatureTyping\"):\n",
    "                            typ = cf.throughFeatureTyping\n",
    "\n",
    "                        if len(typ) > 0:\n",
    "                            used_typ = typ[0]\n",
    "                            used_name = used_typ.basic_name\n",
    "                            used_metatype = used_typ._metatype\n",
    "\n",
    "                        #feature_value_atoms.append(new_ft_classifier)\n",
    "\n",
    "                        # need to do this for Association types and also nested end features\n",
    "\n",
    "                        #ends_to_process = []\n",
    "\n",
    "                        #if hasattr(cf, \"throughEndFeatureMembership\"):\n",
    "                        #    for cf_ele in cf.throughEndFeatureMembership:\n",
    "                        #        ends_to_process.append(cf_ele)\n",
    "                        #if used_typ is not None and hasattr(used_typ, \"throughEndFeatureMembership\"):\n",
    "                        #    for cf_ele in used_typ.throughEndFeatureMembership:\n",
    "                        #        ends_to_process.append(cf_ele)\n",
    "\n",
    "                        for con_end in ends_to_process:\n",
    "                            print(f\"...Inspecting {con_end} for connected features.\")\n",
    "                            if len(con_end.throughReferenceSubsetting) > 0:\n",
    "                                bound_feature = con_end.throughReferenceSubsetting[0]\n",
    "                                bound_feature_type = bound_feature.throughFeatureTyping\n",
    "\n",
    "                                print(f\"...Found connected feature {bound_feature}.\")\n",
    "\n",
    "                                if len(bound_feature_type) > 0:\n",
    "                                    feature_used_type = bound_feature_type[0]\n",
    "\n",
    "                                    if bound_feature._id in bound_features_to_atom_values_dict:\n",
    "                                        # if not enough atoms exist, make some more\n",
    "                                        if (i + 1) > len(bound_features_to_atom_values_dict[bound_feature._id]):\n",
    "                                            print(f\"Executing step 5b (1-to-1 variant). Creating atom #{i + 1} to \" + \\\n",
    "                                                f\"be value for {con_end} and also {bound_feature} to fill in rest of values.\")\n",
    "                                            \n",
    "                                            inspect_type_for_atom_rev_2(input_model,\n",
    "                                                                      package_to_execute,\n",
    "                                                                      package_to_populate,\n",
    "                                                                      i,\n",
    "                                                                      bound_feature,\n",
    "                                                                      feature_used_type,\n",
    "                                                                      bound_features_to_atom_values_dict\n",
    "                                                                     )\n",
    "                                            \n",
    "                                    else:\n",
    "                                        print(f\"Executing step 5b (1-to-1 variant). Creating atom #{i + 1} to \" + \\\n",
    "                                            f\"be value for {con_end} and also {bound_feature}\")\n",
    "                                        \n",
    "                                        if has_type_named(bound_feature, \"FeatureWritePerformance\"):\n",
    "                                            create_feature_write_performance_atoms(\n",
    "                                                input_model,\n",
    "                                                bound_features_to_atom_values_dict,\n",
    "                                                bound_feature,\n",
    "                                                package_to_populate\n",
    "                                            )\n",
    "                                        \n",
    "                                        else:\n",
    "                                            inspect_type_for_atom_rev_2(input_model,\n",
    "                                                                      package_to_execute,\n",
    "                                                                      package_to_populate,\n",
    "                                                                      i,\n",
    "                                                                      bound_feature,\n",
    "                                                                      feature_used_type,\n",
    "                                                                      bound_features_to_atom_values_dict            \n",
    "                                                                     )\n",
    "                                        \n",
    "\n",
    "                        if len(ends_to_process) == 2:\n",
    "                            source_end = ends_to_process[0]\n",
    "                            target_end = ends_to_process[1]\n",
    "\n",
    "                            source_bound_feature = source_end.throughReferenceSubsetting[0]\n",
    "                            target_bound_feature = target_end.throughReferenceSubsetting[0]\n",
    "                            \n",
    "                            try:\n",
    "                                source_atom = bound_features_to_atom_values_dict[source_bound_feature._id][i]\n",
    "                            except KeyError:\n",
    "                                raise KeyError(f\"...Failed to find atoms for {source_bound_feature} and connector {cf}.\" + \\\n",
    "                                               f\"{bound_features_to_atom_values_dict}\")\n",
    "                            \n",
    "                            try:\n",
    "                                target_atom = bound_features_to_atom_values_dict[target_bound_feature._id][i]\n",
    "                            except KeyError:\n",
    "                                raise KeyError(f\"...Failed to find atoms for {target_bound_feature} and connector {cf}.\" + \\\n",
    "                                               f\"{bound_features_to_atom_values_dict}\")\n",
    "\n",
    "                            print(f\"...Typing atom association ends from {source_atom} to {target_atom} under \" + \n",
    "                                 f\"{used_name}{i + 1} to specialize {[ft.basic_name for ft in cf.throughFeatureTyping]}\")\n",
    "                            \n",
    "                            # check for typing\n",
    "                            \n",
    "                            cn_types = cf.throughFeatureTyping\n",
    "                            \n",
    "                            if len(cf.throughFeatureTyping) == 0:\n",
    "                                pass\n",
    "\n",
    "                            new_cn_classifier = build_from_binary_assoc_pattern(\n",
    "                                name=f\"{used_name}{i + 1}\",\n",
    "                                source_role_name=connector_ends[0].basic_name,\n",
    "                                target_role_name=connector_ends[1].basic_name,\n",
    "                                source_type=source_atom,\n",
    "                                target_type=target_atom,\n",
    "                                model=input_model,\n",
    "                                metatype=used_metatype,\n",
    "                                owner=package_to_populate,\n",
    "                                superclasses=cf.throughFeatureTyping,\n",
    "                                specific_fields={}\n",
    "                            )\n",
    "                            \n",
    "                            if cf._id in bound_features_to_atom_values_dict:\n",
    "                                bound_features_to_atom_values_dict[cf._id].append(new_cn_classifier)\n",
    "                            else:\n",
    "                                bound_features_to_atom_values_dict.update({cf._id: [new_cn_classifier]})\n",
    "                            \n",
    "                            connector_atoms.append(new_cn_classifier)\n",
    "                        \n",
    "            \n",
    "    #if type_to_value._metatype in feature_metas():\n",
    "        # Step 1 - create new atom from the classifier\n",
    "        \n",
    "    #    try:\n",
    "            #print(f\"Trying to find metatype for {type_to_value.throughFeatureTyping}\")\n",
    "    #        feature_type = get_most_specific_feature_type(type_to_value)\n",
    "            #feature_type = type_to_value.throughFeatureTyping[0]\n",
    "    #        print(f\"Found type {feature_type} for {type_to_value}.\")\n",
    "            \n",
    "    #        base_name = feature_type.basic_name\n",
    "    #        new_classifier = build_from_classifier_pattern(\n",
    "    #            owner=package_to_populate,\n",
    "    #            name=f\"My{base_name}\",\n",
    "    #            model=input_model,\n",
    "    #            specific_fields={},\n",
    "    #            metatype=type_to_value._metatype,\n",
    "    #            superclasses=[type_to_value]\n",
    "    #        )\n",
    "            \n",
    "    #        print(f\"Executing step 1. Working from {base_name} to create {new_classifier.declaredName}\") \n",
    "            \n",
    "    #    except:\n",
    "    #        print(f\"Cannot find the feature type for {type_to_value.basic_name}\")\n",
    "        \n",
    "    if type_to_value._metatype in datatype_metas():\n",
    "        print(f\"Classifier {type_to_value.basic_name} is a datatype. Bypassing further elaboration.\")\n",
    "        return bound_features_to_atom_values_dict\n",
    "    \n",
    "    elif get_most_specific_feature_type(type_to_value) is not None:\n",
    "        \n",
    "        try:\n",
    "            if get_most_specific_feature_type(type_to_value)._metatype in datatype_metas():\n",
    "                print(f\"Classifier {type_to_value.basic_name} is a datatype or typed by one. Bypassing further elaboration.\")\n",
    "                return bound_features_to_atom_values_dict\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    print(f\"Current values dict is\")\n",
    "    print_values_dictionary(input_model, bound_features_to_atom_values_dict)\n",
    "    \n",
    "    if len(bound_features_to_atom_values_dict.keys()) == 0:\n",
    "        return {}\n",
    "    \n",
    "    if new_classifier == None:\n",
    "        print(f\"...No classifiers created for {type_to_value}\")\n",
    "        try:\n",
    "            new_classifier = bound_features_to_atom_values_dict[type_to_value._id][atom_index]\n",
    "            print(f\"...Classifier for {type_to_value} found in bound values dict as {new_classifier}\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "    else:\n",
    "        print(f\"...Classifier {new_classifier} created for {type_to_value}\")\n",
    "    \n",
    "    embed_values_in_model_atom_classifier_style(\n",
    "        input_model,\n",
    "        bound_features_to_atom_values_dict,\n",
    "        type_to_value,\n",
    "        new_classifier,\n",
    "        package_to_populate\n",
    "    )\n",
    "    \n",
    "    return bound_features_to_atom_values_dict\n",
    "    \n",
    "    #print(f\"Bound features dict: \\n{bound_features_to_atom_values_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27e6cc-2fd8-4890-9c93-a7e8caa1c6ad",
   "metadata": {},
   "source": [
    "## Atom Metadata Load\n",
    "\n",
    "Bring up the Atom metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d104ea-d80a-4c73-ba7e-8bc96c942ce8",
   "metadata": {},
   "source": [
    "filename = \"A-2-Atoms\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "atoms_data = pm.Model.load_from_post_file(json_file)\n",
    "atoms_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42352a-0aa9-4e97-8959-f8fcd026b565",
   "metadata": {},
   "source": [
    "## Annex A.3.2 Without Connectors Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa3d32-7a9f-44b7-abb8-87fc45922128",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-2-WithoutConnectors\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "without_connectors_data = pm.Model.load_from_post_file(json_file)\n",
    "without_connectors_data\n",
    "\n",
    "without_connectors_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd842c-b348-4f13-9c68-6d6d45241d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in without_connectors_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5f94f-5db8-4df1-b528-947dcd45e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in one_2_one_connectors_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448824de-7223-4895-86bf-993497dbd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_2_one_connectors_executor = KermlForwardExecutor(one_2_one_connectors_data, packages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573e8e8-a1fb-4589-8244-65514cbce1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_connectors_to_execute_classifiers = \\\n",
    "    [ele for ele in packages[0].throughOwningMembership if ele._metatype == 'Classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22680e9-33ef-465b-8bb1-76ffa110c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_connectors_executor = KermlForwardExecutor(without_connectors_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a359ea-5462-4f8f-8c0c-18115d80ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca76d4-f55e-4790-ad56-f3e14dd6d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughSubclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3a331-4359-4d3f-bb37-6fe88576baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[2].basic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd51eb-66e8-4241-9abc-d7821f4885a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76527f48-4908-42a8-8115-f9895e2a00af",
   "metadata": {},
   "source": [
    "## Annex A.3.3 One-To-One Connectors Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fe8c2-aa35-45e1-aaa5-d63bf92f629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-3-OneToOneConnectors\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "one_2_one_connectors_data = pm.Model.load_from_post_file(json_file)\n",
    "one_2_one_connectors_data\n",
    "\n",
    "one_2_one_connectors_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3668916-c1c1-4585-8196-c457b142f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in one_2_one_connectors_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51301a43-d790-40b7-be39-33e55febea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[2].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2977955-e553-4c30-8a41-3d8899d219b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[2].throughOwningMembership[1].throughFeatureMembership[0].throughEndFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c2e8d-1270-4a5d-a6f4-72d5a9bb9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_2_one_connectors_executor = KermlForwardExecutor(one_2_one_connectors_data, packages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ce455-334c-44a5-b45e-2d82df1cfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_2_one_connectors_executor.execute_from_classifier(packages[2].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b0dfa-e4d7-4e37-951b-7a49b96e91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[3].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c40ea-1008-4010-aee4-08b53f767027",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[3].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb2b94-e97e-46b9-912e-eb9b9d8eb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[3].throughOwningMembership[4].throughSubclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33368566-8042-4c8d-a2da-d7c70fd1bc7d",
   "metadata": {},
   "source": [
    "## Annex A.3.6 Timing for Behaviors, Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d5aba-7169-41ce-b47d-6c9dc1e35636",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-6-Sequences\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "sequences_data = pm.Model.load_from_post_file(json_file)\n",
    "sequences_data\n",
    "\n",
    "sequences_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736b5cd-3f6f-4a18-b390-1ecf26cd6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in sequences_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305e541-907d-4284-9ef2-7419d2355a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec0f7b-c7a4-4868-b7e2-151c7b9ee3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c528fe2-40d2-4338-96e1-b6312fabac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[1].throughFeatureMembership[0].throughSubsetting[0]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1fa26-79be-4aab-8a74-aa13268317c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_executor = KermlForwardExecutor(sequences_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ad882-269e-4fcc-92e6-cac35b2f2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_executor.execute_from_classifier(packages[0].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021673bf-e141-43b8-9239-d01c1a3d57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca1d1c-8ee3-41eb-b599-12fc0b718d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3180d0-f4ea-46df-8da6-0690a93d5617",
   "metadata": {},
   "source": [
    "## Annex A.3.8 Feature Value Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e873c4-53b3-4d5e-aa73-762461422aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"A-3-8-ChangingFeatureValues\"\n",
    "\n",
    "if not filename.endswith(\".json\"):\n",
    "    filename += \".json\"\n",
    "\n",
    "json_file = Path(Path.cwd()) / \"annex_a_data\" / filename\n",
    "\n",
    "values_data = pm.Model.load_from_post_file(json_file)\n",
    "values_data\n",
    "\n",
    "values_data.reference_other_model(library_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc51fc-9e1a-4941-9b69-57a8419a9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [ele for ele in values_data.elements.values() if ele._metatype == 'Package']\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411f9d6-1ab7-47aa-a4dd-9b4341cfcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02552818-d6a3-45d5-8027-0fd7767c71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_executor = KermlForwardExecutor(values_data, packages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a737f-5f49-4c9d-8f57-e02e6e2d97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20baf9e8-6cfc-4b76-8b24-bcfdec606836",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_type_named(packages[0].throughOwningMembership[3].throughFeatureMembership[1], \"FeatureWritePerformance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd72ec-20da-4d43-8081-2a9802014ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[1].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7e028-f710-403f-9c6e-4f464fb7bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[1].throughFeatureMembership[0].throughFeatureMembership[0].throughFeatureMembership[0].throughSubsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf834ac-42b4-46f5-8e47-bde726074fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_executor.execute_from_classifier(packages[0].throughOwningMembership[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579d9df-eb4d-4766-8980-31ca82927450",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in packages[1].throughOwningMembership:\n",
    "    print(serialize_kerml_atom(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ffce2-eba0-47b3-b5f2-5721783f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c11352-fd73-4918-ae7c-1d408c42b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9902f87-dcf6-44da-a868-949db072a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24319a-617a-4548-8170-6351b9ec24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120a0fe-feee-4d08-b95f-bce2e70d6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughFeatureMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c7cac-9991-4b2e-8a12-bb637bc47e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughParameterMembership[0].throughFeatureValue[0].throughMembership[0].basic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f35260-82e4-444d-9339-06c952ee2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0]\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503d4fc-0e55-4368-a3e9-54776eb0e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first item will be FRE to another feature\n",
    "expression_label = (\n",
    "    expression.throughParameterMembership[0]\n",
    "    .throughFeatureValue[0]\n",
    "    .throughMembership[0]\n",
    "    .basic_name\n",
    ")\n",
    "# check if this is a two-item feature chain or n > 2\n",
    "if \"throughMembership\" in expression._derived and len(expression.throughMembership) > 0:\n",
    "    # if hasattr(expression, \"throughMembership\"):\n",
    "    # this is the n = 2 case\n",
    "    second_item = expression.throughMembership[0].basic_name\n",
    "    expression_label += f\".{second_item}\"\n",
    "else:\n",
    "    # this is the n > 2 case\n",
    "    chains = expression.throughOwningMembership[0].throughFeatureChaining\n",
    "    other_items = \".\".join([chain.basic_name for chain in chains])\n",
    "    expression_label += f\".{other_items}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31860f0c-9c9f-40e9-bc31-fea93dd6fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07727d33-db29-4ba9-8cd7-3cfbaae471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughOwningMembership[0].throughFeatureChaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ed49e-9773-4aba-8870-c4cbb09011f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04353254-2f0f-4802-a155-46ad121d0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureChaining[0].throughMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151fb4d-5bac-454a-a933-7038d4db2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0]._derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157455b-c51a-4c40-a2d4-7ac53a8a7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_data._add_labels(packages[1].throughOwningMembership[3].throughFeatureMembership[19].throughFeatureValue[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14fcfc-1561-4df4-81ad-f049d0695d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypaint1 = get_more_general_types(packages[1].throughOwningMembership[2],0,100)\n",
    "mypaint1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c56014-5eae-4043-bfb5-9a6c7748278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypaint1[1]._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cf6ef-42e3-4689-b714-063fc14589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "derive_inherited_featurememberships(packages[0].throughOwningMembership[3].throughFeatureMembership[0].throughFeatureTyping[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bbd1d-dc9b-4344-a9af-8f50e87a0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[0].throughFeatureTyping[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73f78a-585c-4c8c-9523-eb7fe3907d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[0].throughOwningMembership[3].throughFeatureMembership[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
