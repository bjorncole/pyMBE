{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "universal-silver",
   "metadata": {},
   "source": [
    "# Part Combination Space Exploration\n",
    "\n",
    "This is a notebook developed to leverage the new SysML v2 semantics for nested features and instantiation of models to generate instances of $M_1$ system models as feedstock for analysis pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "import math\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "import networkx as NX\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import ipywidgets as ipyw\n",
    "import traitlets as trt\n",
    "from IPython.display import display\n",
    "\n",
    "import ipyelk\n",
    "import ipyelk.nx\n",
    "from ipyelk.diagram.elk_model import ElkLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-exploration",
   "metadata": {},
   "source": [
    "# Import the SysML v2 API Client\n",
    "> or install if it's missing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import sysml_v2_api_client as sysml2\n",
    "    from sysml_v2_api_client.rest import ApiException\n",
    "except ImportError:\n",
    "    !pip install git+https://github.com/Systems-Modeling/SysML-v2-API-Python-Client.git\n",
    "    print(\n",
    "        \"Had to install the SysML v2 Python API Client.\\n\"\n",
    "        \"Restart the kernel and run the notebook again...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-question",
   "metadata": {},
   "source": [
    "# Configure API Server Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSML_API_BASE_URL = \"http://sysml2-sst.intercax.com:9000\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-arlington",
   "metadata": {},
   "source": [
    "## Activate APIs\n",
    "\n",
    "Configure the API client and instantiate the `Project`, `Commit`, and `Element` APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = sysml2.Configuration(host=SYSML_API_BASE_URL)\n",
    "\n",
    "with sysml2.ApiClient(configuration) as client:\n",
    "    API = dict(\n",
    "        project=sysml2.ProjectApi(client),\n",
    "        commits=sysml2.CommitApi(client),\n",
    "        elements=sysml2.ElementApi(client),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-beauty",
   "metadata": {},
   "source": [
    "## Pull down commits and elements catalogs\n",
    "\n",
    "With the API handles, use the pre-built methods to get lists of commits and elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerbal_proj = [\n",
    "    project\n",
    "    for project in API[\"project\"].get_projects()\n",
    "    if project.name.startswith(\"Kerbal\")\n",
    "    and \"Sat Mar 06 15:49:41 UTC 2021\" in project.name\n",
    "][0]\n",
    "kerbal_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get commits by project\n",
    "try:\n",
    "    commits_response = API[\"commits\"].get_commits_by_project(kerbal_proj.id)\n",
    "    pprint(commits_response)\n",
    "except ApiException as exc:\n",
    "    print(f\"Exception when calling CommitApi->get_commits_by_project: {exc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get commits by project\n",
    "    elements = API[\"elements\"].get_elements_by_project_commit(\n",
    "        kerbal_proj.id,\n",
    "        commits_response[0].id,\n",
    "    )\n",
    "    print(f\"Retrieved {len(elements)} elements.\\n\")\n",
    "    print(\"Here are the first 3 elements:\")\n",
    "    pprint(elements[:3])\n",
    "except ApiException as exc:\n",
    "    elements = []\n",
    "    print(f\"Could not retrieve elements with the ElementApi->get_elements_by_project_commit: {exc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-swing",
   "metadata": {},
   "source": [
    "# Gather Element Data\n",
    "\n",
    "Since the generated API doesn't have much detail for elements, need to do this more hands-on.\n",
    "\n",
    "Not elegant below to just have a larger page size, should implement paging later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_url = (\n",
    "    f\"{SYSML_API_BASE_URL}\"\n",
    "    f\"/projects/{kerbal_proj.id}/commits/{commits_response[0].id}/elements?page[size]=2000\"\n",
    ")\n",
    "elements_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_response = requests.get(elements_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_data = elements_response.json()\n",
    "print(f\"Found data for {len(elements_data)} elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-calgary",
   "metadata": {},
   "source": [
    "Split the elements into relationships and non-relationships. This will let us work with graph representations and a graph understanding of the underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = [\n",
    "    element\n",
    "    for element in elements_data\n",
    "    if 'relatedElement' in element\n",
    "]\n",
    "print(f\"Found {len(relations)} relationship elements.\")\n",
    "\n",
    "non_relations = [\n",
    "    element\n",
    "    for element in elements_data\n",
    "    if not 'relatedElement' in element\n",
    "]\n",
    "print(f\"Found {len(non_relations)} non-relationship elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENTS_TO_SHOW = 25\n",
    "\n",
    "print(f\"Here are the fist {ELEMENTS_TO_SHOW} element names and their types sorted by name:\")\n",
    "list(sorted([\n",
    "    f\"\"\"{element[\"name\"]}: {element[\"@type\"]}\"\"\"\n",
    "    for element in non_relations\n",
    "]))[:ELEMENTS_TO_SHOW]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-costume",
   "metadata": {},
   "source": [
    "# Connect to Semantic Libraries\n",
    "\n",
    "The real work comes in the connection to the $M_1$ layer and then its interpretation at the $M_0$ layer.\n",
    "\n",
    "We will start processing the model here."
   ]
  },
  {
   "attachments": {
    "65b89bcb-18e3-4b18-816b-bfc5a2fe857e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "immune-sellers",
   "metadata": {},
   "source": [
    "## Part Definitions and the Usage Features\n",
    "\n",
    "![image.png](attachment:65b89bcb-18e3-4b18-816b-bfc5a2fe857e.png)\n",
    "\n",
    "The \"parts\" feature will always be typed by Part, any additional features applied to a PartDefinition will subset parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a map for all the elements based on their `id`\n",
    "elements_by_id = {\n",
    "    element[\"@id\"]: element\n",
    "    for element in elements_data\n",
    "}\n",
    "\n",
    "# ...and a map for all the ids of a given type\n",
    "element_ids_by_type = {\n",
    "    type_: [\n",
    "        el[\"@id\"]\n",
    "        for el in elements_data\n",
    "        if el[\"@type\"] == type_\n",
    "    ]\n",
    "    for type_ in set(element[\"@type\"] for element in elements_data)\n",
    "}\n",
    "\n",
    "print(f\"Found {len(element_ids_by_type)} types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_definitions = [\n",
    "    elements_by_id[id_]\n",
    "    for id_ in element_ids_by_type[\"PartDefinition\"]\n",
    "]\n",
    "\n",
    "print(f\"Found {len(part_definitions)} part definitions:\")\n",
    "for part_definition in sorted(part_definitions, key=lambda x: x[\"name\"]):\n",
    "    print(f\"\"\"- {part_definition[\"name\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-ending",
   "metadata": {},
   "source": [
    "Some old code:\n",
    "```python\n",
    "for part_def in part_defs:\n",
    "    id_memo_dict.update({part_def['@id']: part_def})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-routine",
   "metadata": {},
   "source": [
    "## Subclassing Graph\n",
    "\n",
    "Trace the path from the most specialized PartDefinitions back to the library. Pack the results into a graph for later computations on going up and down the specialization tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclasses = [\n",
    "    elements_by_id[id_]\n",
    "    for id_ in element_ids_by_type[\"Superclassing\"]\n",
    "]\n",
    "\n",
    "print(f\"Found {len(superclasses)} superclassing relationships:\")\n",
    "for superclass in superclasses:\n",
    "    specific = superclass[\"specific\"][\"@id\"]\n",
    "    general = superclass[\"general\"][\"@id\"]\n",
    "    print(f\"\"\"- «{elements_by_id[specific][\"name\"]}» :> «{elements_by_id[general][\"name\"]}»\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations[0][\"relatedElement\"][0][\"@id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-object",
   "metadata": {},
   "source": [
    "## Lets create a graph to store the elements and their relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerbal_model = NX.MultiDiGraph()\n",
    "\n",
    "kerbal_model.add_nodes_from(\n",
    "    {\n",
    "        element[\"@id\"]: element\n",
    "        for element in non_relations\n",
    "    }.items()\n",
    ")\n",
    "kerbal_model.add_edges_from([\n",
    "    [\n",
    "        relation[\"relatedElement\"][0][\"@id\"],  # source node (str id)\n",
    "        relation[\"relatedElement\"][1][\"@id\"],  # target node (str id)\n",
    "        relation[\"@type\"],                     # edge type (str name)\n",
    "        relation,                              # edge data (dict)\n",
    "    ]\n",
    "    for relation in relations\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-burning",
   "metadata": {},
   "source": [
    "### We can now draw a superclassing diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diagram_data_to_nodes(nodes):\n",
    "    for id_, node_data in nodes.items():\n",
    "        node_data[\"id\"] = id_\n",
    "        type_label = [ElkLabel(\n",
    "            id=f\"\"\"type_label_for_{id_}\"\"\",\n",
    "            text=f\"\"\"«{node_data[\"@type\"]}»\"\"\",\n",
    "            properties={\n",
    "                \"cssClasses\": \"node_type_label\",\n",
    "            },\n",
    "        )] if \"@type\" in node_data else []\n",
    "        node_data[\"labels\"] = type_label + [node_data[\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgraph(\n",
    "    *,\n",
    "    add_ipyelk_data: bool = True,\n",
    "    edges: (list, tuple) = None,\n",
    "    edge_types: (list, tuple, str) = None,\n",
    "    graph: NX.Graph,\n",
    "):\n",
    "    subgraph = type(graph)()\n",
    "\n",
    "    edges = edges or []\n",
    "\n",
    "    edge_types = edge_types or []\n",
    "    if isinstance(edge_types, str):\n",
    "        edge_types = [edge_types]\n",
    "\n",
    "    if edge_types:\n",
    "        edges += [\n",
    "            (source, target, data)\n",
    "            for (source, target, type_), data in graph.edges.items()\n",
    "            if type_ in edge_types\n",
    "        ]\n",
    "\n",
    "    if not edges:\n",
    "        print(f\"Could not find any edges of type: '{edge_types}'!\")\n",
    "        return subgraph\n",
    "\n",
    "    nodes = {\n",
    "        node_id: graph.nodes[node_id]\n",
    "        for node_id in sum([\n",
    "            [source, target]\n",
    "            for (source, target, data) in edges\n",
    "        ], [])  # sum(a_list, []) flattens a_list\n",
    "    }\n",
    "\n",
    "    add_diagram_data_to_nodes(nodes)\n",
    "\n",
    "    subgraph.add_nodes_from(nodes.items())\n",
    "    subgraph.add_edges_from(edges)\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "superclass_graph = get_subgraph(graph=kerbal_model, edge_types=\"Superclassing\")\n",
    "print(f\"\"\"`superclass_graph` has {len(superclass_graph.nodes)} nodes and {len(superclass_graph.edges)} edges.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diagram(graph: NX.Graph) -> ipyw.HBox:\n",
    "    layouts = ipyelk.nx.XELKTypedLayout()\n",
    "\n",
    "    elk_diagram = ipyelk.Elk(\n",
    "        transformer=ipyelk.nx.XELK(\n",
    "            source=(graph, None),\n",
    "            label_key=\"labels\",\n",
    "            layouts=layouts.value,\n",
    "        ),\n",
    "        style={\n",
    "            \" text.elklabel.node_type_label\": {\n",
    "                \"font-style\": \"italic\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def _element_type_opt_change(change):\n",
    "        elk_diagram.transformer.layouts = layouts.value\n",
    "        elk_diagram.refresh()\n",
    "\n",
    "    layouts.observe(_element_type_opt_change, \"value\")\n",
    "    elk_diagram.layout.flex = \"1\"\n",
    "\n",
    "    return ipyw.HBox([elk_diagram, layouts], layout=dict(height=\"60vh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclass_diagram = make_diagram(superclass_graph)\n",
    "superclass_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make the diagram look a bit better...\n",
    "def set_layout_option(widget, category: str, option: str, value):\n",
    "    category_idxs = [\n",
    "        int(idx)\n",
    "        for idx, name in widget._titles.items()\n",
    "        if name == category\n",
    "    ]\n",
    "    if len(category_idxs) != 1:\n",
    "        raise ValueError(f\"Found {len(category_idxs)} entries for '{category}'!\")\n",
    "    category_widget = widget.children[category_idxs[0]]\n",
    "\n",
    "    option_idxs = [\n",
    "        int(idx)\n",
    "        for idx, name in category_widget._titles.items()\n",
    "        if name == option\n",
    "    ]\n",
    "    if len(option_idxs) != 1:\n",
    "        raise ValueError(f\"Found {len(option_idxs)} entries for '{option}' under '{category}'!\")\n",
    "\n",
    "    category_widget.children[option_idxs[0]].value = value\n",
    "\n",
    "layouts = superclass_diagram.children[1]\n",
    "# Make the direction and label placement look better...\n",
    "set_layout_option(layouts, \"Parents\", \"Direction\", \"UP\")\n",
    "set_layout_option(layouts, \"Label\", \"Node Label Placement\", \"H_CENTER V_TOP INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-device",
   "metadata": {},
   "source": [
    "### We can still use `matplotlib` if we want to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "NX.draw_planar(\n",
    "    superclass_graph,\n",
    "    labels={\n",
    "        node: f\"\"\"{data[\"name\"]}\\n«{data[\"@type\"]}»\"\"\"\n",
    "        for node, data in superclass_graph.nodes.items()\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-builder",
   "metadata": {},
   "source": [
    "### PartUsages\n",
    "\n",
    "Inspect the features of the part definitions that should go into the features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_of_part_uses = element_ids_by_type[\"PartUsage\"]\n",
    "names_of_part_uses = [elements_by_id[id_][\"name\"] for id_ in ids_of_part_uses]\n",
    "\n",
    "print(f\"Found {len(ids_of_part_uses)} part usages: {', '.join(names_of_part_uses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-welsh",
   "metadata": {},
   "source": [
    "Look for `FeatureMemberships` and `TypeFeaturings` to see where the features belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_members = [elements_by_id[id_] for id_ in element_ids_by_type[\"FeatureMembership\"]]\n",
    "type_features = [elements_by_id[id_] for id_ in element_ids_by_type.get(\"TypeFeaturing\", [])]\n",
    "\n",
    "print(f\"Found {len(feature_members)} Feature Members and {len(type_features)} Type Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (fm[\"memberElement\"][\"@id\"], fm[\"owningType\"][\"@id\"], fm)\n",
    "    for fm in feature_members\n",
    "    if elements_by_id[fm[\"memberElement\"][\"@id\"]]['@type'] == 'PartUsage'\n",
    "]\n",
    "\n",
    "part_featuring_graph = get_subgraph(graph=kerbal_model, edges=edges)\n",
    "\n",
    "print(f\"Added {len(edges)} to the Part Featuring Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "[part_featuring_graph.in_degree(node) for node in part_featuring_graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_by_id(id_):\n",
    "    return elements_by_id.get(id_, {}).get(\"name\", None)\n",
    "\n",
    "[\n",
    "    f\"\"\"«{name_by_id(member_element_id)}» is a member of «{name_by_id(owning_type_id)}»\"\"\"\n",
    "    for member_element_id, owning_type_id, *_ in part_featuring_graph.edges\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-brake",
   "metadata": {},
   "source": [
    "#### Draw the parts featuring graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_featuring_diagram = make_diagram(part_featuring_graph)\n",
    "parts_featuring_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the direction and label placement look better...\n",
    "\n",
    "layouts = parts_featuring_diagram.children[1]\n",
    "set_layout_option(layouts, \"Parents\", \"Direction\", \"UP\")\n",
    "set_layout_option(layouts, \"Label\", \"Node Label Placement\", \"H_CENTER V_TOP INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-douglas",
   "metadata": {},
   "source": [
    "### Collect multiplicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicities = [elements_by_id[id_] for id_ in element_ids_by_type[\"MultiplicityRange\"]]\n",
    "integers = [elements_by_id[id_] for id_ in element_ids_by_type[\"LiteralInteger\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element_value(id_: str, key: str):\n",
    "    return elements_by_id.get(id_, {}).get(key, None)\n",
    "\n",
    "def multiplicity_string(multiplicity):\n",
    "    lower = multiplicity[\"lowerBound\"] or {}\n",
    "    upper = multiplicity[\"upperBound\"] or {}\n",
    "    lower = get_element_value(id_=lower.get(\"@id\"), key=\"value\")\n",
    "    upper = get_element_value(id_=upper.get(\"@id\"), key=\"value\")\n",
    "    if upper is None and lower is None:\n",
    "        raise ValueError(\"No multiplicities found in {multiplicity}!\")\n",
    "    return (\n",
    "        f\"\"\"[{\"\" if lower is None else str(lower)}\"\"\"\n",
    "        f\"\"\"{\"..\" if None not in (lower, upper) else \"\"}\"\"\"\n",
    "        f\"\"\"{\"\" if upper is None else str(upper)}]\"\"\"\n",
    "    )\n",
    "\n",
    "multiplicity_strings = [\n",
    "    multiplicity_string(multiplicity)\n",
    "    for multiplicity in multiplicities\n",
    "]\n",
    "multiplicity_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_multiplicity(feature: str, side: str):\n",
    "    if side not in (\"lower\", \"upper\"):\n",
    "        raise ValueError(\"'side' must be 'upper' or 'lower', not '{side}'\")\n",
    "    bound = get_element_value(\n",
    "        id_=(feature[\"multiplicity\"]).get(\"@id\", None),\n",
    "        key=f\"{side}Bound\"\n",
    "    ) or {}\n",
    "    return get_element_value(id_=bound.get(\"@id\"), key=\"value\") or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_uses = [elements_by_id[id_] for id_ in ids_of_part_uses]\n",
    "\n",
    "[\n",
    "    f\"\"\"{part_use[\"name\"]} has multiplicity {get_feature_multiplicity(part_use, \"lower\")}..{get_feature_multiplicity(part_use, \"upper\")}\"\"\"\n",
    "    for part_use in part_uses\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-occasion",
   "metadata": {},
   "source": [
    "### Get feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = [\n",
    "    elements_by_id[feature_typing_id]\n",
    "    for feature_typing_id in element_ids_by_type[\"FeatureTyping\"]\n",
    "]\n",
    "\n",
    "[\n",
    "    f\"\"\"{elements_by_id[ft[\"typedFeature\"][\"@id\"]][\"name\"]} : {elements_by_id[ft[\"type\"][\"@id\"]][\"name\"]}\"\"\"\n",
    "    for ft in feature_types\n",
    "    if elements_by_id[ft[\"typedFeature\"][\"@id\"]][\"name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_type_name(feature):\n",
    "    feature_type = feature[\"type\"]\n",
    "    if feature_type:\n",
    "        return get_element_value(feature_type[0][\"@id\"], \"name\")\n",
    "    else:\n",
    "        return \"Part\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-former",
   "metadata": {},
   "source": [
    "# Generate Instances\n",
    "\n",
    "With the base semantic model in hand, begin to apply the rules to generate our system alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-indonesian",
   "metadata": {},
   "source": [
    "## Find number of instances for feature last positions\n",
    "\n",
    "In SysML, the default type is PartDefinition, which is a Classifier, meaning the minimal interpretation of length one (the specific instance). Nesting parts then have an interpretation as expected by systems engineers, namely that the instances \"stack\" in order to provide a navigation from top-level assembly to leaf component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    f\"\"\"«{part_use[\"name\"]}» \"\"\"\n",
    "    f\"\"\"needs {get_feature_multiplicity(part_use, \"upper\")} \"\"\"\n",
    "    f\"\"\"instances of type «{get_feature_type_name(part_use)}»\"\"\"\n",
    "    for part_use in part_uses\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-burke",
   "metadata": {},
   "source": [
    "Automatically shorten names so that sequences remain readable when printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "short_designator_regex = re.compile(r\"^[A-Z]{2}-[A-Z0-9]+\")\n",
    "\n",
    "def shorten_name(name):\n",
    "    if len(name) < 6:\n",
    "        return name\n",
    "    \n",
    "    # Capture designations\n",
    "    regex_name = short_designator_regex.findall(name)\n",
    "    if regex_name:\n",
    "        return regex_name[0]\n",
    "\n",
    "    # Make acronym\n",
    "    return \"\".join(map(\n",
    "        lambda x: x[0].upper(),\n",
    "        (word for word in name.split()),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instance:\n",
    "    def __init__(self, name: str, index: int):\n",
    "        self.name = shorten_name(name) + '#' + str(index)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"«{self.name}»\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-vision",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "usages_multiplicities = defaultdict(int)\n",
    "for part_use in part_uses:\n",
    "    type_name = get_feature_type_name(part_use)\n",
    "    usages_multiplicities[type_name] += get_feature_multiplicity(part_use, \"upper\")\n",
    "    \n",
    "usages_multiplicities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-translation",
   "metadata": {},
   "source": [
    "## Determine the size of the universe of instances needed for creating alternatives\n",
    "\n",
    "Use feature membership together with multiplicity to decide how many individuals are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-concord",
   "metadata": {},
   "source": [
    "### Building the banded graph\n",
    "\n",
    "Build up a graph with the SysML v1 banded style of part-type-part-type (with superclassing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "banded_feature_graph = NX.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (elem[\"memberElement\"][\"@id\"], elem[\"owningType\"][\"@id\"])\n",
    "    for elem in feature_members\n",
    "    if elements_by_id[elem[\"memberElement\"][\"@id\"]][\"@type\"] == \"PartUsage\"\n",
    "] + [\n",
    "    (elem[\"type\"][\"@id\"], elem[\"typedFeature\"][\"@id\"])\n",
    "    for elem in feature_types\n",
    "    if elements_by_id[elem[\"typedFeature\"][\"@id\"]][\"@type\"] == \"PartUsage\"\n",
    "] + [\n",
    "    (elem[\"specific\"][\"@id\"], elem[\"general\"][\"@id\"])\n",
    "    for elem in superclasses\n",
    "    # if elements_by_id[elem[\"specific\"][\"@id\"]][\"@type\"] == \"PartUsage\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    node_id: elements_by_id[node_id]\n",
    "    for node_id in set(sum(map(list, edges), []))\n",
    "}\n",
    "add_diagram_data_to_nodes(nodes)\n",
    "banded_feature_graph.add_nodes_from(nodes.items())\n",
    "banded_feature_graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "banded_feature_diagram = make_diagram(banded_feature_graph)\n",
    "\n",
    "layouts = banded_feature_diagram.children[1]\n",
    "\n",
    "set_layout_option(layouts, \"Parents\", \"Direction\", \"UP\")\n",
    "set_layout_option(layouts, \"Label\", \"Node Label Placement\", \"H_CENTER V_TOP INSIDE\")\n",
    "\n",
    "banded_feature_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_leaves = [\n",
    "    node_data\n",
    "    for node_id, node_data in part_featuring_graph.nodes.data()\n",
    "    if part_featuring_graph.in_degree(node_id) == 0\n",
    "]\n",
    "[part_leaf['name'] for part_leaf in part_leaves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_roots = [\n",
    "    node_data\n",
    "    for node_id, node_data in part_featuring_graph.nodes.data()\n",
    "    if part_featuring_graph.out_degree(node_id) == 0\n",
    "]\n",
    "[part_root['name'] for part_root in part_roots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "banded_roots = [\n",
    "    node_data\n",
    "    for node_id, node_data in banded_feature_graph.nodes.data()\n",
    "    if banded_feature_graph.out_degree(node_id) == 0\n",
    "]\n",
    "[banded_root['name'] for banded_root in banded_roots]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-mention",
   "metadata": {},
   "source": [
    "Correct the multiplicities by considering nesting.part_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"The rest of the notebook as not been updated yet...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_multiplicity = {}\n",
    "\n",
    "for part_use in part_uses:\n",
    "    corrected_mult = 0\n",
    "    for part_tree_root in banded_roots:\n",
    "        try:\n",
    "            part_path = NX.shortest_path(banded_feature_graph, part_use['@id'], part_tree_root['@id'])\n",
    "            # TODO: check that the path actually exists\n",
    "            corrected_mult = math.prod([feature_upper_multiplicity(id_memo_dict[node]) for node in part_path])\n",
    "        except NX.NetworkXNoPath:\n",
    "            pass\n",
    "    part_multiplicity.update({part_use['@id']: corrected_mult})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-military",
   "metadata": {},
   "source": [
    "### Subdivide Abstract Feature Types\n",
    "\n",
    "Look at the feature types for where they are abstract and then generate instances from the more specific types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "[get_name_by_id(node) for node in subclassing_graph.nodes if subclassing_graph.out_degree(node) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_multiplicity_dict = {}\n",
    "type_id_pairs = {}\n",
    "\n",
    "for part_use in part_uses:\n",
    "    type_name = get_feature_type_name(part_use)\n",
    "    if type_name in corrected_multiplicity_dict:\n",
    "        old_val = corrected_multiplicity_dict[part_use]\n",
    "        corrected_multiplicity_dict.update({type_name: old_val + part_multiplicity[part_use['@id']]})\n",
    "    else:\n",
    "        corrected_multiplicity_dict.update({type_name: part_multiplicity[part_use['@id']]})\n",
    "        if len(part_use['type']) > 0:\n",
    "            type_id_pairs.update({type_name: part_use['type'][0]['@id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_multiplicity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-average",
   "metadata": {},
   "source": [
    "## Generate Random Alternatives\n",
    "\n",
    "Start creating the alternatives with random draws on multiplicity. This will be our space for investigation for weights, thrust-to-weight ratios at stage ignitions, delta-Vs, and initial and burnout masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_alts_to_create = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_multiplicity_dicts = []\n",
    "\n",
    "for step in range(0, no_alts_to_create):\n",
    "\n",
    "    partitioned_multiplicity_dict = {}\n",
    "\n",
    "    for key in corrected_multiplicity_dict:\n",
    "        if key in type_id_pairs:\n",
    "            key_id = type_id_pairs[key]\n",
    "            type_obj = id_memo_dict[key_id]\n",
    "            if type_obj['isAbstract']:\n",
    "                local_partition = {}\n",
    "                if key_id in subclassing_graph.nodes:\n",
    "                    no_splits = len(list(subclassing_graph.successors(key_id)))\n",
    "                    taken = 0\n",
    "                    for indx, succ in enumerate(subclassing_graph.successors(key_id)):\n",
    "                        if indx < no_splits - 1:\n",
    "                            draw = random.randint(0, corrected_multiplicity_dict[key])\n",
    "                            taken = taken + draw\n",
    "                        else:\n",
    "                            draw = corrected_multiplicity_dict[key] - taken\n",
    "                        local_partition.update({get_name_by_id(succ): draw})\n",
    "                partitioned_multiplicity_dict.update({key: local_partition})\n",
    "            else:\n",
    "                partitioned_multiplicity_dict.update({key: corrected_multiplicity_dict[key]})\n",
    "                \n",
    "    partitioned_multiplicity_dicts.append(partitioned_multiplicity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_multiplicity_dicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-tours",
   "metadata": {},
   "source": [
    "- [ ] TODO: Fix the dictionary to have keys as IDs, not name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance_dicts = []\n",
    "classifier_memo_dicts = []\n",
    "\n",
    "for step in range(0, no_alts_to_create):\n",
    "\n",
    "    classifier_instance_dict = {}\n",
    "    classifier_memo_dict = {}\n",
    "    \n",
    "    partitioned_multiplicity_dict = partitioned_multiplicity_dicts[step]\n",
    "\n",
    "    for mult_key in partitioned_multiplicity_dict:\n",
    "        instances_list = []\n",
    "        if isinstance(partitioned_multiplicity_dict[mult_key], dict):\n",
    "            for special_key in partitioned_multiplicity_dict[mult_key]:\n",
    "                sub_instances_list = []\n",
    "                instances_number = (partitioned_multiplicity_dict[mult_key][special_key] + 1)\n",
    "                for index in range(1, instances_number):\n",
    "                    new_instance = Instance(special_key, index)\n",
    "                    instances_list.append(new_instance)\n",
    "                    sub_instances_list.append(new_instance)\n",
    "                    classifier_memo_dict.update({new_instance.name: [special_key, mult_key]})\n",
    "                classifier_instance_dict.update({special_key: sub_instances_list})\n",
    "            classifier_instance_dict.update({mult_key: instances_list})\n",
    "        else:\n",
    "            instances_number = (corrected_multiplicity_dict[mult_key] + 1)\n",
    "            for index in range(1, instances_number):\n",
    "                new_instance = Instance(mult_key, index)\n",
    "                instances_list.append(new_instance)\n",
    "                classifier_memo_dict.update({new_instance.name: [mult_key]})\n",
    "            classifier_instance_dict.update({mult_key: instances_list})\n",
    "            \n",
    "    classifier_instance_dicts.append(classifier_instance_dict)\n",
    "    classifier_memo_dicts.append(classifier_memo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-final",
   "metadata": {},
   "source": [
    "Now that the universe of instances has been calculated, we can look at how they can be sequenced. This method is probably fragile so will need revisions.\n",
    "In this case, found that it can't handle unconnected featuring graph components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "[get_name_by_id(node) for node in NX.topological_sort(part_featuring_graph.reverse())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in NX.connected_components(part_featuring_graph.to_undirected()):\n",
    "    connected_sub = NX.subgraph(part_featuring_graph, list(comp))\n",
    "    sorted_feature_groups.append(\n",
    "        [node for node in NX.topological_sort(connected_sub.reverse())]\n",
    "    )\n",
    "    print([get_name_by_id(node) for node in NX.topological_sort(connected_sub.reverse())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier_instance_dict in classifier_instance_dicts:\n",
    "\n",
    "    for part_tree_root in part_roots:\n",
    "        root_name = get_name_by_id(part_tree_root['@id'])\n",
    "        if root_name not in classifier_instance_dict:\n",
    "            classifier_instance_dict.update({root_name: Instance(root_name, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-passport",
   "metadata": {},
   "source": [
    "The topological sort on the graph of feature membership determines the order in which to build up sets of instances for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sequence_dictionaries = []\n",
    "\n",
    "for step in range(0, no_alts_to_create):\n",
    "    \n",
    "    classifier_instance_dict = classifier_instance_dicts[step]\n",
    "    \n",
    "    feature_sequence_dictionary = {}\n",
    "    covered_draw_dict = {}\n",
    "    \n",
    "    for sorting in sorted_feature_groups:\n",
    "        for indx, node in enumerate(sorting):\n",
    "            if indx > 0:\n",
    "                new_dict = {}\n",
    "                # get current parent from the graph\n",
    "                for pred in part_featuring_graph.successors(node):\n",
    "                    current_parent = pred\n",
    "                    #print(get_name_by_id(current_parent))\n",
    "\n",
    "                sequence_of_sequences = []\n",
    "\n",
    "                for sequence in feature_sequence_dictionary[current_parent]:\n",
    "\n",
    "                    test_mult = random.randint(\n",
    "                        feature_lower_multiplicity(id_memo_dict[node]),\n",
    "                        feature_upper_multiplicity(id_memo_dict[node])\n",
    "                    )\n",
    "\n",
    "                    for ind_j in range(0, test_mult):\n",
    "                        new_sequence = copy.deepcopy(sequence)\n",
    "                        # find the type of the current feature node\n",
    "                        node_type = get_feature_type_name(id_memo_dict[node])\n",
    "\n",
    "                        need_draw = True\n",
    "                        \n",
    "                        safety_count = 0\n",
    "\n",
    "                        while(need_draw and safety_count < 100):\n",
    "\n",
    "                            draw = random.randint(\n",
    "                                0,\n",
    "                                corrected_multiplicity_dict[node_type] - 1\n",
    "                            )\n",
    "                            #print(classifier_instance_dict[node_type][draw])\n",
    "\n",
    "                            if node_type in covered_draw_dict:\n",
    "                                if classifier_instance_dict[node_type][draw] in covered_draw_dict[node_type]:\n",
    "                                    pass\n",
    "                                    #need_draw = False\n",
    "                                else:\n",
    "                                    covered_draw_dict[node_type].append(classifier_instance_dict[node_type][draw])\n",
    "                                    need_draw = False\n",
    "                            else:\n",
    "                                covered_draw_dict.update({node_type : [classifier_instance_dict[node_type][draw]]})\n",
    "                                need_draw = False\n",
    "\n",
    "                            safety_count = safety_count + 1\n",
    "                            if safety_count == 99:\n",
    "                                print('Safety count hit when trying to place ' + \n",
    "                                      str(classifier_instance_dict[node_type][draw]) + ' under ' +\n",
    "                                     str(new_sequence))\n",
    "                                print('Covered dict is ' + str(covered_draw_dict[node_type]))\n",
    "                        \n",
    "                        new_sequence.append(classifier_instance_dict[node_type][draw])\n",
    "\n",
    "                        sequence_of_sequences.append(new_sequence)\n",
    "\n",
    "                feature_sequence_dictionary.update({node: sequence_of_sequences})\n",
    "\n",
    "            elif indx == 0:\n",
    "                if isinstance(classifier_instance_dict[get_name_by_id(node)], list):\n",
    "                    starter_list = []\n",
    "                    for item in classifier_instance_dict[get_name_by_id(node)]:\n",
    "                        starter_list.append([item])\n",
    "                    # handle case where main type has more than one instance\n",
    "                    feature_sequence_dictionary.update({node: starter_list})\n",
    "                    #print(starter_list)\n",
    "                    if len(starter_list) == 0:\n",
    "                        break\n",
    "                else:\n",
    "                    feature_sequence_dictionary.update({node: [[classifier_instance_dict[get_name_by_id(node)]]]})\n",
    "            \n",
    "    feature_sequence_dictionaries.append(feature_sequence_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx, feature_sequence_dictionary in enumerate(feature_sequence_dictionaries):\n",
    "    if indx < 3:\n",
    "        print(\"Solution #\" + str(indx))\n",
    "        for key in feature_sequence_dictionary:\n",
    "            print(get_name_by_id(key) + ', id ' + key)\n",
    "            for seq in feature_sequence_dictionary[key]:\n",
    "                print(str(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-general",
   "metadata": {},
   "source": [
    "# Analyze and Explore Resulting Space\n",
    "\n",
    "Now that the alternatives have been generated, we can explore the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[get_name_by_id(node), node] for node in subclassing_graph.nodes if subclassing_graph.out_degree(node) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-spell",
   "metadata": {},
   "source": [
    "## Gather AttributeUsages and literal values\n",
    "\n",
    "Find all the attribute usages so we can navigate to them from our parts library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-month",
   "metadata": {},
   "source": [
    "TODO: Look at using FeatureValue relationships for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att_literal_values(att_use):\n",
    "    literal_values = []\n",
    "    for att_member in att_use['ownedMember']:\n",
    "        if att_member['@id'] in id_memo_dict:\n",
    "            if id_memo_dict[att_member['@id']]['@type'] == 'LiteralReal':\n",
    "                literal_values.append(id_memo_dict[att_member['@id']])\n",
    "                \n",
    "    return literal_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_uses = [att_use for att_use in non_relations if att_use['@type'] == 'AttributeUsage']\n",
    "for att_use in att_uses:\n",
    "    id_memo_dict.update({att_use['@id']: att_use})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-richards",
   "metadata": {},
   "source": [
    "Get literal reals to connect to attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = [real for real in non_relations if real['@type'] == 'LiteralReal']\n",
    "for real in reals:\n",
    "    id_memo_dict.update({real['@id']: real})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-hamburg",
   "metadata": {},
   "source": [
    "Create objects to hold different values per instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueHolder():\n",
    "    \n",
    "    def __init__(self, path, name, value):\n",
    "        # path is list of instance references\n",
    "        self.holder_string = ''\n",
    "        for indx, step in enumerate(path):\n",
    "            if indx == 0:\n",
    "                self.holder_string = str(step)\n",
    "            else:\n",
    "                self.holder_string = self.holder_string + '.' + str(step)\n",
    "        self.holder_string = self.holder_string + '.' + name\n",
    "        self.value = value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.value is not None:\n",
    "            return self.holder_string + ' (' + str(self.value) + ')'\n",
    "        else:\n",
    "            return self.holder_string + ' (unset)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-writing",
   "metadata": {},
   "source": [
    "Get expressions attached to attributes as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_ele = [found for found in non_relations if found['@id'] == 'ced4f691-07ff-45dd-a2cd-687bc3bb8942']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_values = {}\n",
    "\n",
    "for att_use in att_uses:\n",
    "    if len(att_use['ownedMember']) > 0:\n",
    "        typ = id_memo_dict[att_use['owningType']['@id']]\n",
    "        for att_member in att_use['ownedMember']:\n",
    "            for value in get_att_literal_values(att_use):\n",
    "                print (att_use['name'] + ' of ' + typ['name'] + ' = ' + str(value['value']))\n",
    "                if att_use['name'] in type_values:\n",
    "                    type_values[att_use['name']].update({typ['name']: value['value']})\n",
    "                else:\n",
    "                    type_values.update({att_use['name']: {typ['name']: value['value']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-clause",
   "metadata": {},
   "source": [
    "- [ ] TODO: Factor the above as sequences of instances rather than going back to the type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-intro",
   "metadata": {},
   "source": [
    "## Create Attribute Sequences\n",
    "\n",
    "Add attributes to the sequences for parts, and where there are values, add those to the sequence also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_member_value_graph = NX.DiGraph()\n",
    "\n",
    "for att in att_uses:\n",
    "    if att['@id'] in id_memo_dict:\n",
    "        if id_memo_dict[att['@id']]['@type'] == 'AttributeUsage':\n",
    "            attribute_member_value_graph.add_edge(att['@id'], att['owningType']['@id'])\n",
    "            for value in get_att_literal_values(att):\n",
    "                attribute_member_value_graph.add_edge(value['@id'], att['@id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_member_value_graph_labels = {}\n",
    "for node in attribute_member_value_graph.nodes():\n",
    "    if id_memo_dict[node]['@type'] == 'AttributeUsage':\n",
    "        attribute_member_value_graph_labels.update({node: get_name_by_id(node)})\n",
    "    elif id_memo_dict[node]['@type'] == 'LiteralReal':\n",
    "        attribute_member_value_graph_labels.update({node: id_memo_dict[node]['value']})\n",
    "    \n",
    "NX.draw_spring(attribute_member_value_graph, labels=attribute_member_value_graph_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-century",
   "metadata": {},
   "source": [
    "### Match Attributes to Classifier types\n",
    "\n",
    "Where the owningType of the Attribute usage is a classifier, use it as the base of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_value_dicts = []\n",
    "value_holders = []\n",
    "\n",
    "for classifier_instance_dict in classifier_instance_dicts:\n",
    "\n",
    "    att_value_dict = {}\n",
    "\n",
    "    for att in att_uses:\n",
    "        new_sequences = []\n",
    "        att_owning_type = id_memo_dict[att['owningType']['@id']]\n",
    "        if att_owning_type['@type'] == 'PartDefinition':\n",
    "            if att_owning_type['name'] in classifier_instance_dict:\n",
    "                for instance in classifier_instance_dict[att_owning_type['name']]:\n",
    "                    new_sequence = []\n",
    "                    new_sequence.append(instance)\n",
    "                    \n",
    "                    #new_sequence.append(att['name'])\n",
    "                    \n",
    "                    for value in get_att_literal_values(att):\n",
    "                        #new_sequence.append(value['@id'])\n",
    "                        new_holder = ValueHolder([instance], att['name'], value['value'])\n",
    "                        value_holders.append(new_holder)\n",
    "                        new_sequence.append(new_holder)\n",
    "                        \n",
    "                    if len(get_att_literal_values(att)) == 0:\n",
    "                        new_holder = ValueHolder([instance], att['name'], None)\n",
    "                        new_sequence.append(new_holder)\n",
    "                    new_sequences.append(new_sequence)\n",
    "\n",
    "        att_value_dict.update({att['@id']: new_sequences})\n",
    "        \n",
    "    att_value_dicts.append(att_value_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx, att_value_dict in enumerate(att_value_dicts):\n",
    "    if indx < 3:\n",
    "        print(\"Solution #\" + str(indx))\n",
    "        for key in att_value_dict:\n",
    "            print(get_name_by_id(key) + ', id ' + key)\n",
    "            for indx, seq in enumerate(att_value_dict[key]):\n",
    "                if indx < 5:\n",
    "                    seq_string = []\n",
    "                    for member in seq:\n",
    "                        if isinstance(member, str) and member in id_memo_dict:\n",
    "                            obj = id_memo_dict[member]\n",
    "                            # TODO: Create unique value objects for formula mapping\n",
    "                            if obj['@type'] == 'LiteralReal':\n",
    "                                seq_string.append(str(obj['value']) + ', id ' + member)\n",
    "                        else:\n",
    "                            seq_string.append(member)\n",
    "                    print(seq_string)\n",
    "                elif indx == 5:\n",
    "                    print('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-junction",
   "metadata": {},
   "source": [
    "## Gather Expressions and Invocations and Build Expression Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_graph = NX.DiGraph()\n",
    "expression_graph_labels = {}\n",
    "expression_graph_ascii = ''\n",
    "\n",
    "invocations = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-modem",
   "metadata": {},
   "source": [
    "Memoize InvocationExpressions, BlockExpressions, FeatureReferenceExpressions, and ReferenceUsages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocations = [invocation for invocation in non_relations if invocation['@type'] == 'InvocationExpression']\n",
    "functions = [function for function in non_relations if function['@type'] == 'Function']\n",
    "op_exprs = [function for function in non_relations if function['@type'] == 'OperatorExpression']\n",
    "block_exprs = [block_expr for block_expr in non_relations if block_expr['@type'] == 'BlockExpression']\n",
    "feature_refs = [feature_ref for feature_ref in non_relations if feature_ref['@type'] == 'FeatureReferenceExpression']\n",
    "reference_uses = [ref_use for ref_use in non_relations if ref_use['@type'] == 'ReferenceUsage']\n",
    "\n",
    "para_members = [para_member for para_member in relations if para_member['@type'] == 'ParameterMembership']\n",
    "res_expr_members = [res_expr_member for res_expr_member in relations if res_expr_member['@type'] == 'ResultExpressionMembership']\n",
    "ret_para_members = [ret_para_member for ret_para_member in relations if ret_para_member['@type'] == 'ReturnParameterMembership']\n",
    "\n",
    "for invocation in invocations:\n",
    "    id_memo_dict.update({invocation['@id']: invocation})\n",
    "    \n",
    "for function in functions:\n",
    "    id_memo_dict.update({function['@id']: function})\n",
    "    \n",
    "for op_expr in op_exprs:\n",
    "    id_memo_dict.update({op_expr['@id']: op_expr})\n",
    "    \n",
    "for block_expr in block_exprs:\n",
    "    id_memo_dict.update({block_expr['@id']: block_expr})\n",
    "    \n",
    "for feature_ref in feature_refs:\n",
    "    id_memo_dict.update({feature_ref['@id']: feature_ref})\n",
    "    \n",
    "for reference_use in reference_uses:\n",
    "    id_memo_dict.update({reference_use['@id']: reference_use})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofms = []\n",
    "ofms.extend(para_members)\n",
    "ofms.extend(res_expr_members)\n",
    "ofms.extend(ret_para_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-decrease",
   "metadata": {},
   "source": [
    "Get feature memberships from the expressions to their members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fm in feature_members:\n",
    "    if fm['owningType']['@id'] in id_memo_dict:\n",
    "        if id_memo_dict[fm['owningType']['@id']]['@type'] == 'InvocationExpression':\n",
    "            expression_graph.add_edge(fm['owningType']['@id'], fm['memberFeature']['@id'])\n",
    "        if id_memo_dict[fm['owningType']['@id']]['@type'] == 'Function':\n",
    "            expression_graph.add_edge(fm['owningType']['@id'], fm['memberFeature']['@id'])\n",
    "            expression_graph_labels.update({fm['owningType']['@id']: id_memo_dict[fm['owningType']['@id']]['name']})\n",
    "        if id_memo_dict[fm['owningType']['@id']]['@type'] == 'OperatorExpression':\n",
    "            expression_graph.add_edge(fm['owningType']['@id'], fm['memberFeature']['@id'])\n",
    "            expression_graph_labels.update({fm['owningType']['@id']: id_memo_dict[fm['owningType']['@id']]['operator']})\n",
    "            if fm['memberFeature']['@id'] in id_memo_dict:\n",
    "                if id_memo_dict[fm['memberFeature']['@id']]['@type'] == 'FeatureReferenceExpression':\n",
    "                    expression_graph_labels.update({fm['memberFeature']['@id']: \n",
    "                                                   id_memo_dict[id_memo_dict[fm['memberFeature']['@id']]['referent']['@id']]['name'] + ' (FeatRef)'})\n",
    "\n",
    "for ofm in ofms:\n",
    "    if ofm['owningType']['@id'] in id_memo_dict:\n",
    "        if id_memo_dict[ofm['owningType']['@id']]['@type'] == 'BlockExpression':\n",
    "            expression_graph.add_edge(ofm['owningType']['@id'], ofm['memberFeature']['@id'])\n",
    "            if ofm['memberFeature']['@id'] in id_memo_dict:\n",
    "                if id_memo_dict[ofm['memberFeature']['@id']]['@type'] == 'FeatureReferenceExpression':\n",
    "                    expression_graph_labels.update({ofm['memberFeature']['@id']: \n",
    "                                                   id_memo_dict[id_memo_dict[ofm['memberFeature']['@id']]['referent']['@id']]['name'] + ' (FeatRef)'})\n",
    "            if get_name_by_id(ofm['memberFeature']['@id']) is not None:\n",
    "                if get_metatype_by_id(ofm['memberFeature']['@id']) == 'ReferenceUsage':\n",
    "                    ref_type_name = id_memo_dict[id_memo_dict[ofm['memberFeature']['@id']]['type'][0]['@id']]['name']\n",
    "                    expression_graph_labels.update({ofm['memberFeature']['@id']: \n",
    "                                                    get_name_by_id(ofm['memberFeature']['@id']) + ':' + ref_type_name})\n",
    "                else:\n",
    "                    expression_graph_labels.update({ofm['memberFeature']['@id']: get_name_by_id(ofm['memberFeature']['@id'])})\n",
    "                    \n",
    "for ft in feature_types:\n",
    "    if ft['typedFeature']['@id'] in id_memo_dict:\n",
    "        if id_memo_dict[ft['type']['@id']]['@type'] == 'Function':\n",
    "            expression_graph.add_edge(ft['typedFeature']['@id'], ft['type']['@id'])\n",
    "            expression_graph_labels.update({ft['type']['@id']: id_memo_dict[ft['type']['@id']]['name']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-alabama",
   "metadata": {},
   "source": [
    "Gather the body and parameters of the invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "NX.draw_spring(expression_graph, labels=expression_graph_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-player",
   "metadata": {},
   "source": [
    "## Perform Staging Mass Analysis\n",
    "\n",
    "- [ ] TODO: Strengthen this with analyses that actually do the calculation\n",
    "- [ ] TODO: Accommodate associations between tanks and engines to make delta-V and Isp calculations work properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-deficit",
   "metadata": {},
   "source": [
    "This is very specific to a given calculation - need to have a kernel for expanding the calculations just as with inspecting type hierarchy and multiplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx, feature_sequence_dictionary in enumerate(feature_sequence_dictionaries):\n",
    "    no_stages = len(feature_sequence_dictionary['31a4436f-07fd-48c6-b503-9d186d925c3c'])\n",
    "    print(str(no_stages))\n",
    "    for stag in range(1, no_stages + 1):\n",
    "        stage_empty_mass = 0\n",
    "        stage_full_mass = 0\n",
    "        stage_specific_impulse = 0\n",
    "        # add up the starter mass for the stage and the burnout mass\n",
    "        stage_instance = feature_sequence_dictionary['31a4436f-07fd-48c6-b503-9d186d925c3c'][stag - 1][-1]\n",
    "        print(str(stage_instance) + \": \" + str(classifier_memo_dicts[indx][stage_instance.name]))\n",
    "        if '54c2e565-ede4-4c12-a44c-2277566a2861' in feature_sequence_dictionary:\n",
    "            booster_instances = \\\n",
    "                [booster[-1] for booster in feature_sequence_dictionary['54c2e565-ede4-4c12-a44c-2277566a2861']\n",
    "                     if str(booster[0]) == str(stage_instance)]\n",
    "            print('Booster instance length = ' + str(len(booster_instances)))\n",
    "            for booster in booster_instances:\n",
    "                for clz in classifier_memo_dicts[indx][booster.name]:\n",
    "                    if clz in partitioned_multiplicity_dicts[indx]:\n",
    "                        pass\n",
    "                    else:\n",
    "                        empty_mass = type_values['Empty Mass'][clz]\n",
    "                        full_mass = type_values['Full Mass'][clz]\n",
    "                        specific_impulse = type_values['Specific Impulse'][clz]\n",
    "\n",
    "                        stage_empty_mass = stage_empty_mass + empty_mass\n",
    "                        stage_full_mass = stage_full_mass + full_mass\n",
    "                        stage_specific_impulse = stage_specific_impulse + specific_impulse\n",
    "            if len(booster_instances) > 0:\n",
    "                stage_specific_impulse = stage_specific_impulse / len(booster_instances)\n",
    "        \n",
    "        if stage_empty_mass > 0.0:\n",
    "            booster_delta_V = 9.81 * stage_specific_impulse * math.log(stage_full_mass / stage_empty_mass)\n",
    "        \n",
    "        if indx < 3:\n",
    "            print ('Stage booster full mass is ' + str(stage_full_mass))\n",
    "            print ('Stage booster empty mass is ' + str(stage_empty_mass))\n",
    "            print ('Stage booster specific impulse is ' + str(stage_specific_impulse))\n",
    "            print ('Stage booster delta-V is ' + str(booster_delta_V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-schema",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
